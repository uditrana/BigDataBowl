{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 6 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import dask.dataframe as dd\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(nb_workers=6)\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_plays' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ab63c4fc2601>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# get bal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mmin_dist_off\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_plays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'playId'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gameId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_nearest_player_off\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0mmin_dist_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_plays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'playId'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gameId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_nearest_player_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_plays' is not defined"
     ]
    }
   ],
   "source": [
    "# helper functions to get nearest offensive and defensive players in grouped df\n",
    "def get_nearest_player(df):\n",
    "    df = df[df.event.isin(['pass_arrived'])]\n",
    "    if len(df) == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    ball_end = df[df.nflId == 0][['x', 'y']].head(1)\n",
    "    assert len(ball_end) == 1, print(len(ball_end))\n",
    "    \n",
    "    players_end = df[(df.nflId != 0) & (df.team_pos == 'OFF')][['x', 'y']]\n",
    "    min_dist = np.linalg.norm(players_end.values - ball_end.values, axis=1).min()\n",
    "    \n",
    "    return min_dist\n",
    "\n",
    "def get_nearest_player_off(df):\n",
    "    df = df[df.event.isin(['pass_arrived'])]\n",
    "    if len(df) == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    ball_end = df[df.nflId == 0][['x', 'y']].head(1)\n",
    "    assert len(ball_end) == 1, print(len(ball_end))\n",
    "    \n",
    "    players_end = df[(df.nflId != 0) & (df.team_pos == 'OFF')][['x', 'y']]\n",
    "    min_dist = np.linalg.norm(players_end.values - ball_end.values, axis=1).min()\n",
    "    \n",
    "    return min_dist\n",
    "\n",
    "def get_nearest_player_def(df):\n",
    "    df = df[df.event.isin(['pass_arrived'])]\n",
    "    if len(df) == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    ball_end = df[df.nflId == 0][['x', 'y']].head(1)\n",
    "    assert len(ball_end) == 1, print(len(ball_end))\n",
    "    \n",
    "    players_end = df[(df.nflId != 0) & (df.team_pos == 'DEF')][['x', 'y']]\n",
    "    min_dist = np.linalg.norm(players_end.values - ball_end.values, axis=1).min()\n",
    "    \n",
    "    return min_dist\n",
    "\n",
    "# get bal\n",
    "min_dist_off = all_plays.groupby(['playId', 'gameId']).apply(get_nearest_player_off).reset_index()\n",
    "min_dist_def = all_plays.groupby(['playId', 'gameId']).apply(get_nearest_player_def).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plays Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlaysDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        # load csvs\n",
    "        tracking_df = pd.read_csv(os.path.join(data_dir, 'week1_norm.csv'))\n",
    "\n",
    "        # get valid frames for tuning from tracking df (consider every pass, labels are 1 if there is a player close by)\n",
    "        #tracking_df = tracking_df[tracking_df['event'].isin(['pass_forward', 'pass_arrived', \n",
    "        #    'pass_outcome_caught', 'pass_outcome_incomplete', 'pass_outcome_touchdown', 'pass_outcome_intercepted'])]\n",
    "        pass_forward_plays = tracking_df[tracking_df['event'] == 'pass_forward'][['gameId', 'playId']].drop_duplicates()\n",
    "        pass_attempted_plays = tracking_df[tracking_df['event'] == 'pass_arrived'][['gameId', 'playId']].drop_duplicates()\n",
    "        tracking_df = pass_forward_plays.merge(pass_attempted_plays.merge(tracking_df, on=['gameId', 'playId']), on=['gameId', 'playId'])\n",
    "        \n",
    "        # calculate ball ending position\n",
    "        ball_end = tracking_df[(tracking_df.nflId == 0) & (tracking_df.event == 'pass_arrived')][['gameId', 'playId', 'x', 'y']]\n",
    "        ball_end = ball_end.rename(columns={'x': 'ball_x', 'y': 'ball_y'})\n",
    "\n",
    "        # remove plays where ball is thrown out of bounds\n",
    "        ball_end = ball_end[(ball_end.ball_x <= 119.5) & (ball_end.ball_x >= 0.5) & (ball_end.ball_y <= 53.5) & (ball_end.ball_y >= -0.5)]\n",
    "        \n",
    "        # merge tracking_df with ball_end\n",
    "        tracking_df = tracking_df[tracking_df.nflId != 0].merge(ball_end, on=['gameId', 'playId'])\n",
    "                \n",
    "        # for each player, label whether they reached the ball (radius of 1.5 yds)\n",
    "        self.player_reached = tracking_df[tracking_df.event == 'pass_arrived'][['gameId', 'playId', 'nflId', 'x', 'y', 'ball_x', 'ball_y']]\n",
    "        self.player_reached['close_to_ball'] = np.less_equal(np.linalg.norm(np.stack([self.player_reached.x.values,\n",
    "                    self.player_reached.y.values], axis=-1) - np.stack([self.player_reached.ball_x.values,\n",
    "                    self.player_reached.ball_y.values], axis=-1), axis=1), 1.5).astype(int)\n",
    "        \n",
    "        # store tracking_df\n",
    "        self.all_plays = tracking_df\n",
    "        \n",
    "        # turn play list into np array\n",
    "        self.play_list = tracking_df[['gameId', 'playId']].drop_duplicates().values\n",
    "        \n",
    "        # max number of players per play\n",
    "        self.max_num = 17\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.play_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        gameId = self.play_list[idx, 0]\n",
    "        playId = self.play_list[idx, 1]\n",
    "        \n",
    "        # load frame, sigma_label, and ball_end\n",
    "        frame = self.all_plays[(self.all_plays.gameId == gameId) & (self.all_plays.playId == playId)]\n",
    "        sigma_label = self.player_reached[(self.player_reached.gameId == gameId) & (self.player_reached.playId == playId)][['nflId', 'close_to_ball']]\n",
    "        \n",
    "        try:\n",
    "            ball_end = self.player_reached[(self.player_reached.gameId == gameId) & (self.player_reached.playId == playId)][['ball_x', 'ball_y']].iloc[0].values\n",
    "        except IndexError:\n",
    "            print(self.player_reached[(self.player_reached.gameId == gameId) & (self.player_reached.playId == playId)])\n",
    "            raise IndexError\n",
    "        # clean up frame (remove QB, merge with sigma_label, ball_end, remove pass_arrived event)\n",
    "        frame = frame.loc[frame.position != 'QB'].merge(sigma_label, on='nflId')\n",
    "        frame = frame.replace('OFF', 1)\n",
    "        frame = frame.replace('DEF', 0)\n",
    "        try:\n",
    "            frame['tof'] = pd.to_timedelta(pd.to_datetime(frame[frame.event == 'pass_arrived'].time.iloc[0]) - pd.to_datetime(frame[frame.event == 'pass_forward'].time.iloc[0])).total_seconds()\n",
    "        except IndexError:\n",
    "            print(frame[frame.event == 'pass_arrived'])\n",
    "            print(frame[frame.event == 'pass_forward'])\n",
    "            raise IndexError\n",
    "        frame['ball_x'] = ball_end[0]\n",
    "        frame['ball_y'] = ball_end[1]\n",
    "        frame = frame[frame.event == 'pass_forward']\n",
    "\n",
    "        # generate data, label, fill missing data\n",
    "        data = torch.tensor(frame[['nflId', 'x', 'y', 'v_x', 'v_y', 'a_x', 'a_y', 'team_pos', 'ball_x', 'ball_y', 'tof']].values).float()\n",
    "        label = torch.tensor(frame['close_to_ball'].values)\n",
    "        if data.size(0) < self.max_num:\n",
    "            data = torch.cat([data, torch.ones([self.max_num - data.size(0), data.size(1)])], dim=0)\n",
    "            label = torch.cat([label, torch.zeros([self.max_num - label.size(0)])], dim=0)\n",
    "        \n",
    "        return data, label.long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completion Probability Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompProbModel(torch.nn.Module):\n",
    "    def __init__(self, a_max=7, s_max=9, avg_ball_speed=20, tti_sigma=0.5, tti_lambda=1.0):\n",
    "        super().__init__()\n",
    "        \n",
    "        # define parameters and whether or not to optimize\n",
    "        self.a_max = Parameter(torch.tensor([a_max]), requires_grad=False).float()\n",
    "        self.s_max = Parameter(torch.tensor([s_max]), requires_grad=False).float()\n",
    "        self.avg_ball_speed = Parameter(torch.tensor([avg_ball_speed]), requires_grad=False).float()\n",
    "        self.tti_sigma = Parameter(torch.tensor([tti_sigma]), requires_grad=True).float()\n",
    "        self.tti_lambda = Parameter(torch.tensor([tti_lambda]), requires_grad=True).float()\n",
    "        self.reax_t = self.s_max / self.a_max\n",
    "        self.pi = torch.tensor([3.1416])\n",
    "\n",
    "        \n",
    "        # define field grid\n",
    "        self.x = torch.linspace(0.5, 119.5, 120)\n",
    "        self.y = torch.linspace(-0.5, 53.5, 55)\n",
    "        self.y[0] = -0.2\n",
    "        xx, yy = torch.meshgrid(self.x, self.y)\n",
    "        self.field_locs = Parameter(torch.flatten(torch.stack((xx, yy), dim=-1), end_dim=-2), requires_grad=False)  # (F, 2)\n",
    "        self.T = Parameter(torch.linspace(0.1, 4, 40), requires_grad=False) # (T,)\n",
    "    \n",
    "    def forward(self, frame):\n",
    "        v_x_r = frame[:, :, 5] * self.reax_t + frame[:, :, 3]\n",
    "        v_y_r = frame[:, :, 6] * self.reax_t + frame[:, :, 4]\n",
    "        v_r_mag = torch.norm(torch.stack([v_x_r, v_y_r], dim=-1), dim=-1)\n",
    "        v_r_theta = torch.arctan(v_y_r / v_x_r)\n",
    "        # fill nan\n",
    "        v_r_theta[v_r_theta != v_r_theta] = 0\n",
    "\n",
    "        x_r = frame[:, :, 1] + frame[:, :, 3] * self.reax_t + 0.5 * frame[:, :, 5] * self.reax_t**2\n",
    "        y_r = frame[:, :, 2] + frame[:, :, 4] * self.reax_t + 0.5 * frame[:, :, 6] * self.reax_t**2\n",
    "        \n",
    "        # get each player's team, location, and velocity\n",
    "        #player_teams = frame[:, :, -1] # J,\n",
    "        reaction_player_locs = torch.stack([x_r, y_r], dim=-1).int() # (J, 2)\n",
    "        reaction_player_vels = torch.stack([v_x_r, v_y_r], dim=-1) #(J, 2)\n",
    "        \n",
    "        # calculate each player's distance from each field location\n",
    "        int_d_vec = self.field_locs.unsqueeze(1).unsqueeze(0) - reaction_player_locs.unsqueeze(1) #F, J, 2\n",
    "        int_d_mag = torch.norm(int_d_vec, dim=-1) # F, J\n",
    "        \n",
    "        # take dot product of velocity and direction\n",
    "        int_s0 = torch.clip(torch.sum(int_d_vec * reaction_player_vels.unsqueeze(1), dim=-1) / int_d_mag, -1 * self.s_max.item(), self.s_max.item()) #F, J\n",
    "        #int_s0 = torch.sum(int_d_vec * reaction_player_vels.unsqueeze(1), dim=-1) / int_d_mag\n",
    "        \n",
    "        # calculate time it takes for each player to reach each field position accounting for their current velocity and acceleration\n",
    "        t_lt_smax = (self.s_max - int_s0) / self.a_max  #F, J,\n",
    "        d_lt_smax = t_lt_smax * ((int_s0 + self.s_max) / 2) #F, J,\n",
    "        d_at_smax = int_d_mag - d_lt_smax               #F, J,\n",
    "        t_at_smax = d_at_smax / self.s_max              #F, J,\n",
    "        t_tot = self.reax_t + t_lt_smax + t_at_smax     # F, J,\n",
    "\n",
    "        # subtract the arrival time (t_tot) from time of flight of ball\n",
    "        int_dT = self.T.view(1, 1, -1, 1) - t_tot.unsqueeze(2)         #F, T, J\n",
    "        \n",
    "        # calculate interception probability for each player, field loc, time of flight (logistic function)\n",
    "        p_int = 1. / (1. + torch.exp(-1 * self.pi / (torch.sqrt(torch.tensor([3.0])) / self.tti_sigma * int_dT))) #F, T, J\n",
    "        \n",
    "        # get p_int for actual tof\n",
    "        tof = torch.round(frame[:, 0, -1] * 10).long().view(-1, 1, 1, 1).repeat(1, p_int.size(1), 1, p_int.size(-1))\n",
    "        p_int = torch.gather(p_int, 2, tof).squeeze() # F, J\n",
    "        \n",
    "        # index into ball position\n",
    "        ball_end_x = frame[:, 0, -3].int()\n",
    "        ball_end_y = frame[:, 0, -2].int()\n",
    "        ball_field_ind = (ball_end_y * self.x.shape[0] + ball_end_x).long().view(-1, 1, 1).repeat(1, 1, p_int.size(-1))\n",
    "        \n",
    "        p_int = torch.gather(p_int, 1, ball_field_ind).squeeze()\n",
    "        \n",
    "        return p_int\n",
    "        \n",
    "        # TODO(adit98) change this\n",
    "        #lambda_z = torch.where((traj_locs_z<3) & (traj_locs_z>0), 1, 0) #F, T, T\n",
    "        # apply lambda\n",
    "        # probs = probs * lambda_z.unsqueeze(-1) * lambda_dt\n",
    "        # norm_factor = torch.maximum(1., probs.sum(dim=-1))  #F, T, T\n",
    "        # probs_norm = (probs / norm_factor[..., None])  #F, T, T, J\n",
    "        \n",
    "        # check if this is valid\n",
    "\n",
    "        # compute reach vecs (path of ball)\n",
    "        #reach_vecs = ball_start - field_locs  # (F, 2)\n",
    "        \n",
    "        # invert direction signs\n",
    "        #dx = -1 * reach_vecs[:, 0]\n",
    "        #dy = -1 * reach_vecs[:, 1]\n",
    "\n",
    "        # calculate ball velocity for each possible time of flight (0 to 4)\n",
    "        #vx = dx.unsqueeze(-1) / T.unsqueeze(0)\n",
    "        #vy = dy.unsqueeze(-1) / T.unsqueeze(0)\n",
    "        #g = 10.72468 # gravitation constant (yards/s^2)\n",
    "        #vz_0 = (T * g) / 2\n",
    "\n",
    "        # calculate every (x, y, z) location that ball passes through\n",
    "        # note that idx (i, j, k) into below arrays is invalid when j < k\n",
    "        #traj_ts = torch.tile(T, (len(field_locs), len(T), 1)) #(F, T, T)\n",
    "        #traj_locs_x_idx = torch.round(torch.clip((ball_start[0]+vx.unsqueeze(-1)*T), 0, len(x)-1)) # F, T, T\n",
    "        #traj_locs_y_idx = torch.round(torch.clip((ball_start[1]+vy.unsqueeze(-1)*T), 0, len(y)-1)) # F, T, T\n",
    "        #traj_locs_z = 2.0+vz_0.view(1, -1, 1)*traj_ts-0.5*g*traj_ts*traj_ts #F, T, T\n",
    "        \n",
    "        # TODO(adit98) fix this\n",
    "        #path_idxs = torch.ravel_multi_index(torch.stack((traj_locs_y_idx, traj_locs_x_idx)).reshape(2, -1), xx.shape)  # (F*T*T,)\n",
    "        #traj_t_idxs = torch.round(10*traj_ts - 1).flatten()  # (F, T, T)\n",
    "        #probs = p_int[path_idxs, t] # F*T*T, J\n",
    "        #probs = probs.reshape((*traj_locs_x_idx.shape, len(reaction_player_locs)))  # F, T, T, J\n",
    "        \n",
    "        # TODO(adit98) this is where to add lambda tuning\n",
    "        #lambda_dt = 1\n",
    "        #probs = probs * lambda_z.unsqueeze(-1) * lambda_dt\n",
    "        #norm_factor = torch.maximum(1., probs.sum(dim=-1))  #F, T, T\n",
    "        #probs_norm = (probs / norm_factor[..., None])  #F, T, T, J\n",
    "\n",
    "        #total_probs = torch.sum(probs_norm, dim=-1)  # F, T, T\n",
    "        #compl_total_probs = 1 - total_probs  # F, T, T\n",
    "        #remaining_compl_probs = torch.cumprod(compl_total_probs, dim=-1)  # F, T, T\n",
    "        #off_probs = torch.sum(probs_norm * player_teams, dim=-1)\n",
    "        #def_probs = torch.sum(probs_norm * (1 - player_teams), dim=-1)\n",
    "\n",
    "        # maximum 0 because if it goes negative the pass has been caught by then and theres no residual probability\n",
    "\n",
    "        #shift_compl_cumsum = torch.roll(remaining_compl_probs, 1, dim=-1)  # F, T, T\n",
    "        #shift_compl_cumsum[:, :, 0] = 1\n",
    "        #total_completion_prob_dt = shift_compl_cumsum * total_probs  # F, T, T\n",
    "        #total_completion_prob = torch.cumsum(total_completion_prob_dt, dim=-1)  # F, T, T\n",
    "\n",
    "        #completion_prob_off_dt = shift_compl_cumsum * off_probs  # F, T, T\n",
    "        #completion_prob_def_dt = shift_compl_cumsum * def_probs  # F, T, T\n",
    "        #completion_prob_off = torch.cumsum(completion_prob_off_dt, dim=-1)  # F, T, T\n",
    "        #completion_prob_def = torch.cumsum(completion_prob_def_dt, dim=-1)  # F, T, T\n",
    "        \n",
    "        # this einsum takes the diagonal values over the last two axes\n",
    "        # where T = t. this takes care of the t > T issue.\n",
    "        #throw_p_int_off = torch.einsum('ijj->ij', total_completion_prob_off)  # F, T\n",
    "        #throw_p_int_def = torch.einsum('ijj->ij', total_completion_prob_def)  # F, T\n",
    "        #throw_p_int = torch.einsum('ijj->ij', total_completion_prob)  # F, T\n",
    "        \n",
    "        # below gets cutoff for combined model\n",
    "        #field_p_int_off = throw_p_int_off.mean(dim=1)  # F,\n",
    "        #field_p_int_def = throw_p_int_def.mean(dim=1)  # F,\n",
    "        #field_p_int = throw_p_int.mean(dim=1)  # F,\n",
    "\n",
    "        #field_p_no_int = 1-field_p_int\n",
    "\n",
    "        #field_df = pd.DataFrame({\n",
    "        #    'ball_start_x': ball_start[0],\n",
    "        #    'ball_start_y': ball_start[1], \n",
    "        #    'ball_end_x': field_locs[:,0],\n",
    "        #    'ball_end_y': field_locs[:,1],\n",
    "        #    'p_mass_1': (((field_p_int_off-field_p_int_def)+1.)/2.).round(3),\n",
    "        #    'p_mass_2': field_p_no_int.round(3),\n",
    "            # 'p_mass_players': p_int_norm,\n",
    "        #})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Dataset, Model and Run Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = PlaysDataset(data_dir = '../data/')\n",
    "loader = torch.utils.data.DataLoader(ds, batch_size=16, num_workers=4, shuffle=True)\n",
    "data, label = ds[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
      "Wall time: 4.53 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-8655082099df>:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for data, target in tqdm(loader):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8060eb353b7642a6b178d488e6754ab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=49.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.5000], requires_grad=True)\n",
      "tensor([[0.4704, 0.4792, 0.4787, 0.4799, 0.4762, 0.4796, 0.4741, 0.4662, 0.4770,\n",
      "         0.4751, 0.4799, 0.4814, 0.4792, 0.4771, 0.4700, 0.4215, 0.4215],\n",
      "        [0.4636, 0.4619, 0.4666, 0.4684, 0.4620, 0.4484, 0.4427, 0.4451, 0.4385,\n",
      "         0.4657, 0.4649, 0.4560, 0.4768, 0.4768, 0.4768, 0.4768, 0.4768],\n",
      "        [0.4405, 0.3727, 0.3727, 0.4437, 0.4330, 0.4456, 0.4495, 0.4582, 0.4226,\n",
      "         0.4384, 0.4374, 0.4615, 0.4762, 0.4762, 0.4762, 0.4762, 0.4762],\n",
      "        [0.4400, 0.4522, 0.4424, 0.4694, 0.4386, 0.4513, 0.4465, 0.4650, 0.4655,\n",
      "         0.4482, 0.4336, 0.4684, 0.4644, 0.4644, 0.4644, 0.4644, 0.4644],\n",
      "        [0.4832, 0.4759, 0.4808, 0.4823, 0.4832, 0.4754, 0.4764, 0.4787, 0.4815,\n",
      "         0.4720, 0.4795, 0.4829, 0.4394, 0.4394, 0.4394, 0.4394, 0.4394],\n",
      "        [0.4377, 0.3779, 0.4466, 0.4470, 0.4484, 0.4408, 0.4708, 0.4661, 0.4552,\n",
      "         0.4339, 0.4537, 0.4065, 0.4145, 0.4767, 0.4767, 0.4767, 0.4767],\n",
      "        [0.4744, 0.4733, 0.4706, 0.4780, 0.4668, 0.4728, 0.4652, 0.4728, 0.4761,\n",
      "         0.4774, 0.4778, 0.4671, 0.4536, 0.4536, 0.4536, 0.4536, 0.4536],\n",
      "        [0.4535, 0.4591, 0.4575, 0.4677, 0.4119, 0.4263, 0.4383, 0.4439, 0.4552,\n",
      "         0.4206, 0.4699, 0.4656, 0.4549, 0.4549, 0.4549, 0.4549, 0.4549],\n",
      "        [0.4775, 0.4764, 0.4806, 0.4685, 0.4615, 0.4679, 0.4622, 0.4581, 0.4710,\n",
      "         0.4714, 0.4588, 0.4811, 0.4701, 0.4534, 0.4534, 0.4534, 0.4534],\n",
      "        [0.4000, 0.4493, 0.4523, 0.4152, 0.4421, 0.4446, 0.4567, 0.4374, 0.4353,\n",
      "         0.4333, 0.4517, 0.4522, 0.4761, 0.4761, 0.4761, 0.4761, 0.4761],\n",
      "        [0.4470, 0.4604, 0.4634, 0.4675, 0.4450, 0.4698, 0.4606, 0.4756, 0.4767,\n",
      "         0.4671, 0.4682, 0.4596, 0.4781, 0.4781, 0.4781, 0.4781, 0.4781],\n",
      "        [0.4433, 0.4459, 0.4501, 0.4677, 0.4503, 0.4613, 0.4370, 0.4671, 0.4301,\n",
      "         0.4048, 0.4348, 0.4568, 0.4287, 0.4745, 0.4745, 0.4745, 0.4745],\n",
      "        [0.4707, 0.4709, 0.4559, 0.4616, 0.4604, 0.4450, 0.4761, 0.4607, 0.4579,\n",
      "         0.4738, 0.4624, 0.4592, 0.4753, 0.4771, 0.4771, 0.4771, 0.4771],\n",
      "        [0.4662, 0.4439, 0.4482, 0.4527, 0.4475, 0.4502, 0.4335, 0.4547, 0.4571,\n",
      "         0.4656, 0.4549, 0.4147, 0.4770, 0.4770, 0.4770, 0.4770, 0.4770],\n",
      "        [0.4555, 0.4444, 0.4497, 0.4520, 0.4620, 0.4647, 0.4635, 0.4490, 0.4682,\n",
      "         0.4681, 0.4429, 0.4626, 0.4615, 0.4776, 0.4776, 0.4776, 0.4776],\n",
      "        [0.4370, 0.4620, 0.4494, 0.3869, 0.4605, 0.4336, 0.4673, 0.3841, 0.4368,\n",
      "         0.4697, 0.4583, 0.4568, 0.4581, 0.4581, 0.4581, 0.4581, 0.4581]],\n",
      "       grad_fn=<SqueezeBackward0>) tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor(0.6219, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "Parameter containing:\n",
      "tensor([nan], requires_grad=True)\n",
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "       grad_fn=<SqueezeBackward0>) tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]])\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "all elements of input should be between 0 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-8655082099df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/big_data_bowl/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/big_data_bowl/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/big_data_bowl/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2523\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2525\u001b[0;31m     return torch._C._nn.binary_cross_entropy(\n\u001b[0m\u001b[1;32m   2526\u001b[0m         input, target, weight, reduction_enum)\n\u001b[1;32m   2527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: all elements of input should be between 0 and 1"
     ]
    }
   ],
   "source": [
    "%time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "model = CompProbModel()\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.000001)\n",
    "for data, target in tqdm(loader):\n",
    "    output = model(data)\n",
    "    print(output, target)\n",
    "    loss = loss_fn(output, target.float())\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.tti_sigma\n",
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load files\n",
    "data_dir = '../data/'\n",
    "tracking_df = pd.read_csv('../data/week1_norm.csv')\n",
    "plays_df = pd.read_csv('../data/plays.csv')\n",
    "\n",
    "#print(tracking_df.columns)\n",
    "\n",
    "# get valid frames for tuning from tracking df\n",
    "tracking_df = tracking_df[tracking_df['event'].isin(['pass_forward', 'pass_arrived', \n",
    "    'pass_outcome_caught', 'pass_outcome_incomplete', 'pass_outcome_touchdown', 'pass_outcome_intercepted'])]\n",
    "tracking_df['valid_frame'] = tracking_df['event'].str.contains('pass_forward')\n",
    "tracking_df = tracking_df.groupby(['playId', 'gameId']).filter(lambda l: l['valid_frame'].any()).reset_index()\n",
    "\n",
    "# merge tracking df and plays df\n",
    "all_plays = plays_df.merge(tracking_df, how='left', on=['playId', 'gameId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-09 17:04:03+00:00\n",
      "2018-09-09 17:04:04.500000+00:00\n",
      "1.5\n"
     ]
    }
   ],
   "source": [
    "play = tracking_df[(tracking_df.playId == 81) & (tracking_df.gameId == 2018090902)]\n",
    "print(pd.to_timedelta(pd.to_datetime(play[play.event == 'pass_arrived'].time.iloc[0]) - pd.to_datetime(play[play.event == 'pass_forward'].time.iloc[0])).total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracking_df[tracking_df.position != 'QB'][['gameId', 'playId', 'nflId']].drop_duplicates().groupby(['gameId', 'playId']).nflId.count().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.085102305866526\n",
      "1.6439466513218899\n",
      "4.790180627434475\n",
      "2.435306899869004\n"
     ]
    }
   ],
   "source": [
    "min_dist_off = min_dist_off.rename(columns={0:'ball_dist'})\n",
    "complete_passes = all_plays.loc[all_plays.event.isin(['pass_outcome_caught', 'pass_outcome_touchdown'])][['gameId', 'playId']]\n",
    "incomplete_passes = all_plays.loc[all_plays.event.isin(['pass_outcome_incomplete'])][['gameId', 'playId']]\n",
    "\n",
    "print(complete_passes.merge(min_dist_off).drop_duplicates().ball_dist.median())\n",
    "print(incomplete_passes.merge(min_dist_off).drop_duplicates().ball_dist.mean())\n",
    "\n",
    "min_dist_def = min_dist_def.rename(columns={0:'ball_dist'})\n",
    "complete_passes = all_plays.loc[all_plays.event.isin(['pass_outcome_caught', 'pass_outcome_touchdown'])][['gameId', 'playId']]\n",
    "incomplete_passes = all_plays.loc[all_plays.event.isin(['pass_outcome_incomplete'])][['gameId', 'playId']]\n",
    "\n",
    "print(complete_passes.merge(min_dist_def).drop_duplicates().ball_dist.mean())\n",
    "print(incomplete_passes.merge(min_dist_def).drop_duplicates().ball_dist.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_plays.loc[(all_plays.gameId == 2018090600) & (all_plays.playId == 146)][['displayName', 'x', 'y']]\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from visualize2 import AnimatePlay\n",
    "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n",
    "play_df = tracking_df[(tracking_df.gameId == 2018091000) & (tracking_df.playId == 3016)]\n",
    "\n",
    "animated_play = AnimatePlay(play_df, 20)#play_df[play_df.frameId <= 46], 20)\n",
    "HTML(animated_play.ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_nearest_player(play_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
