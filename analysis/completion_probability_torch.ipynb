{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import dask.dataframe as dd\n",
    "import torch\n",
    "from enum import Enum\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(nb_workers=6)\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TuningParam(Enum):\n",
    "    sigma = 1\n",
    "    lamb = 2\n",
    "TUNING = TuningParam.lamb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plays Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlaysDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_dir, all_weeks=False, event_filter=None):\n",
    "        # event_filter should be 'pass_forward' for sigma, 'pass_arrived' for lambda\n",
    "        self.event_filter = event_filter\n",
    "        if all_weeks:\n",
    "            all_data = []\n",
    "            for week in range(5, 10):\n",
    "                all_data.append(pd.read_csv(os.path.join(data_dir, 'week%d_norm.csv' % week)))\n",
    "                \n",
    "            tracking_df = pd.concat(all_data)\n",
    "            \n",
    "        else:\n",
    "            # load csvs\n",
    "            tracking_df = pd.read_csv(os.path.join(data_dir, 'week1_norm.csv'))\n",
    "\n",
    "        #tracking_df = tracking_df[tracking_df['event'].isin(['pass_forward', 'pass_arrived', \n",
    "        #    'pass_outcome_caught', 'pass_outcome_incomplete', 'pass_outcome_touchdown', 'pass_outcome_intercepted'])]\n",
    "        \n",
    "        # get valid frames for tuning from tracking df (consider every pass, labels are 1 if there is a player close by)\n",
    "        pass_forward_plays = tracking_df[tracking_df['event'] == 'pass_forward'][['gameId', 'playId']].drop_duplicates()\n",
    "        pass_attempted_plays = tracking_df[tracking_df['event'] == 'pass_arrived'][['gameId', 'playId']].drop_duplicates()\n",
    "        tracking_df = pass_forward_plays.merge(pass_attempted_plays.merge(tracking_df, on=['gameId', 'playId']), on=['gameId', 'playId'])\n",
    "        \n",
    "        # calculate ball ending position\n",
    "        ball_end = tracking_df[(tracking_df.nflId == 0) & (tracking_df.event == 'pass_arrived')][['gameId', 'playId', 'x', 'y']]\n",
    "        ball_end = ball_end.rename(columns={'x': 'ball_end_x', 'y': 'ball_end_y'})\n",
    "        \n",
    "        # calculate ball position at throw\n",
    "        ball_start = tracking_df[(tracking_df.nflId == 0) & (tracking_df.event == 'pass_forward')][['gameId', 'playId', 'x', 'y']]\n",
    "        ball_start = ball_start.rename(columns={'x': 'ball_start_x', 'y': 'ball_start_y'})\n",
    "        \n",
    "        ball_start_end = ball_end.merge(ball_start, on=['gameId', 'playId'])\n",
    "        # remove plays where ball is thrown out of bounds\n",
    "        ball_start_end = ball_start_end[(ball_start_end.ball_end_x <= 119.5) & (ball_start_end.ball_end_x >= 0.5) & (ball_start_end.ball_end_y <= 53.5) & (ball_start_end.ball_end_y >= -0.5)]\n",
    "        \n",
    "        # remove frames with more than 17 non-QB players' tracking data\n",
    "        tracking_df = tracking_df[(tracking_df.position != 'QB') & (tracking_df.nflId != 0)].groupby(['gameId', 'playId']).filter(lambda x: len(x.nflId.unique()) <= 17)\n",
    "        \n",
    "        # merge tracking_df with ball_end and ball_start\n",
    "        tracking_df = tracking_df[tracking_df.nflId != 0].merge(ball_start_end, on=['gameId', 'playId'])\n",
    "        # for each player, label whether they reached the ball (radius of 1.5 yds)\n",
    "        self.player_reached = tracking_df[tracking_df.event == 'pass_arrived'][['gameId', 'playId', 'nflId', 'team_pos', 'event', 'x', 'y', 'ball_end_x', 'ball_end_y', 'ball_start_x', 'ball_start_y']]\n",
    "        self.player_reached['close_to_ball'] = np.less_equal(np.linalg.norm(np.stack([self.player_reached.x.values,\n",
    "                    self.player_reached.y.values], axis=-1) - np.stack([self.player_reached.ball_end_x.values,\n",
    "                    self.player_reached.ball_end_y.values], axis=-1), axis=1), 1.5).astype(int)\n",
    "        # control is given by (player is on offense) XOR (ball is caught)\n",
    "        self.player_reached['control_ball'] = ((self.player_reached['team_pos'] == 'OFF') ^ self.player_reached['event'].isin(['pass_outcome_caught', 'pass_outcome_touchdown'])).astype(int)\n",
    "        \n",
    "        # store tracking_df\n",
    "        self.all_plays = tracking_df\n",
    "        \n",
    "        # turn play list into np array\n",
    "        self.play_list = tracking_df[['gameId', 'playId']].drop_duplicates().values\n",
    "        \n",
    "        # max number of players per play\n",
    "        self.max_num = 17\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.play_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        gameId = self.play_list[idx, 0]\n",
    "        playId = self.play_list[idx, 1]\n",
    "        \n",
    "        # load frame, sigma_label, and ball_end\n",
    "        frame = self.all_plays[(self.all_plays.gameId == gameId) & (self.all_plays.playId == playId)]\n",
    "        sigma_lambda_label = self.player_reached[(self.player_reached.gameId == gameId) & (self.player_reached.playId == playId)][['nflId', 'close_to_ball', 'control_ball']]\n",
    "        \n",
    "        try:\n",
    "            ball_end = self.player_reached[(self.player_reached.gameId == gameId) & (self.player_reached.playId == playId)][['ball_end_x', 'ball_end_y']].iloc[0].values\n",
    "            ball_start = self.player_reached[(self.player_reached.gameId == gameId) & (self.player_reached.playId == playId)][['ball_start_x', 'ball_start_y']].iloc[0].values\n",
    "        except IndexError:\n",
    "            print(self.player_reached[(self.player_reached.gameId == gameId) & (self.player_reached.playId == playId)])\n",
    "            raise IndexError\n",
    "        # clean up frame (remove QB, merge with sigma_lambda_label, ball_end, remove pass_arrived event)\n",
    "        frame = frame.loc[frame.position != 'QB'].merge(sigma_lambda_label, on='nflId')\n",
    "        frame = frame.replace('OFF', 1)\n",
    "        frame = frame.replace('DEF', 0)\n",
    "        try:\n",
    "            frame['tof'] = pd.to_timedelta(pd.to_datetime(frame[frame.event == 'pass_arrived'].time.iloc[0]) - pd.to_datetime(frame[frame.event == 'pass_forward'].time.iloc[0])).total_seconds()\n",
    "        except IndexError:\n",
    "            print(frame[frame.event == 'pass_arrived'])\n",
    "            print(frame[frame.event == 'pass_forward'])\n",
    "            raise IndexError\n",
    "        frame['ball_end_x'] = ball_end[0]\n",
    "        frame['ball_end_y'] = ball_end[1]\n",
    "        frame['ball_start_x'] = ball_start[0]\n",
    "        frame['ball_start_y'] = ball_start[1]\n",
    "        if self.event_filter is not None:\n",
    "            frame = frame[frame.event == self.event_filter]\n",
    "\n",
    "        # generate data, label, fill missing data\n",
    "        \n",
    "        # SS changed for lambda\n",
    "        if TUNING == TuningParam.lamb:\n",
    "            data = torch.tensor(frame.loc[frame.close_to_ball == 1, ['nflId', 'x', 'y', 'v_x', 'v_y', 'a_x', 'a_y', 'team_pos', 'ball_end_x', 'ball_end_y', 'ball_start_x', 'ball_start_y', 'tof']].values).float()\n",
    "            label = torch.tensor(frame.loc[frame.close_to_ball == 1, 'control_ball'].values)\n",
    "        elif TUNING == TuningParam.sigma:\n",
    "            data = torch.tensor(frame[['nflId', 'x', 'y', 'v_x', 'v_y', 'a_x', 'a_y', 'team_pos', 'ball_end_x', 'ball_end_y', 'ball_start_x', 'ball_start_y', 'tof']].values).float()\n",
    "            label = torch.tensor(frame['close_to_ball'].values)\n",
    "        \n",
    "        if data.size(0) < self.max_num:\n",
    "            data = torch.cat([data, torch.ones([self.max_num - data.size(0), data.size(1)])], dim=0)\n",
    "            label = torch.cat([label, torch.zeros([self.max_num - label.size(0)])], dim=0)\n",
    "        \n",
    "        return data, label.long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completion Probability Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompProbModel(torch.nn.Module):\n",
    "    def __init__(self, a_max=7.0, s_max=9.0, avg_ball_speed=20.0, tti_sigma=0.5, tti_lambda_off=1.0, tti_lambda_def=1.0):\n",
    "        super().__init__()\n",
    "        \n",
    "        # define parameters and whether or not to optimize\n",
    "        self.tti_sigma = Parameter(torch.tensor([tti_sigma]), requires_grad=False).float()\n",
    "        self.tti_lambda_off = Parameter(torch.tensor([tti_lambda_off]), requires_grad=True).float()\n",
    "        self.tti_lambda_def = Parameter(torch.tensor([tti_lambda_def]), requires_grad=True).float()\n",
    "        self.a_max = Parameter(torch.tensor([a_max]), requires_grad=False).float()\n",
    "        self.s_max = Parameter(torch.tensor([s_max]), requires_grad=False).float()\n",
    "        self.reax_t = Parameter(self.s_max / self.a_max, requires_grad=False).float()\n",
    "        self.avg_ball_speed = Parameter(torch.tensor([avg_ball_speed]), requires_grad=False).float()\n",
    "        self.g = Parameter(torch.tensor([10.72468]), requires_grad=False) #y/s/s\n",
    "        self.z_max = Parameter(torch.tensor([3.]), requires_grad=False)\n",
    "        self.z_min = Parameter(torch.tensor([0.]), requires_grad=False)\n",
    "        \n",
    "        # define field grid\n",
    "        self.x = torch.linspace(0.5, 119.5, 120)\n",
    "        self.y = torch.linspace(-0.5, 53.5, 55)\n",
    "        self.y[0] = -0.2\n",
    "        self.xx, self.yy = torch.meshgrid(self.x, self.y)\n",
    "        self.field_locs = Parameter(torch.flatten(torch.stack((self.xx, self.yy), dim=-1), end_dim=-2), requires_grad=False)  # (F, 2)\n",
    "        self.T = Parameter(torch.linspace(0.1, 4, 40), requires_grad=False) # (T,)\n",
    "        \n",
    "    \n",
    "    def forward(self, frame):\n",
    "        # TODO SS get ball_start\n",
    "        ball_start = frame[:, :, 3:]\n",
    "        reach_vecs = self.field_locs - ball_start\n",
    "        reach_dist = torch.linalg.norm(reach_vecs, dim=-1)\n",
    "        \n",
    "        v_x_r = frame[:, :, 5] * self.reax_t + frame[:, :, 3]\n",
    "        v_y_r = frame[:, :, 6] * self.reax_t + frame[:, :, 4]\n",
    "        v_r_mag = torch.norm(torch.stack([v_x_r, v_y_r], dim=-1), dim=-1)\n",
    "        v_r_theta = torch.atan2(v_y_r, v_x_r)\n",
    "        \n",
    "        x_r = frame[:, :, 1] + frame[:, :, 3] * self.reax_t + 0.5 * frame[:, :, 5] * self.reax_t**2\n",
    "        y_r = frame[:, :, 2] + frame[:, :, 4] * self.reax_t + 0.5 * frame[:, :, 6] * self.reax_t**2\n",
    "        \n",
    "        # get each player's team, location, and velocity\n",
    "        player_teams = frame[:, :, 7] # J,\n",
    "        reaction_player_locs = torch.stack([x_r, y_r], dim=-1).int() # (J, 2)\n",
    "        reaction_player_vels = torch.stack([v_x_r, v_y_r], dim=-1) #(J, 2)\n",
    "        \n",
    "        # calculate each player's distance from each field location\n",
    "        int_d_vec = self.field_locs.unsqueeze(1).unsqueeze(0) - reaction_player_locs.unsqueeze(1) #F, J, 2\n",
    "        int_d_mag = torch.norm(int_d_vec, dim=-1) # F, J\n",
    "        \n",
    "        # take dot product of velocity and direction\n",
    "        int_s0 = torch.clip(torch.sum(int_d_vec * reaction_player_vels.unsqueeze(1), dim=-1) / int_d_mag, -1 * self.s_max.item(), self.s_max.item()) #F, J\n",
    "        #int_s0 = torch.sum(int_d_vec * reaction_player_vels.unsqueeze(1), dim=-1) / int_d_mag\n",
    "        \n",
    "        # calculate time it takes for each player to reach each field position accounting for their current velocity and acceleration\n",
    "        t_lt_smax = (self.s_max - int_s0) / self.a_max  #F, J,\n",
    "        d_lt_smax = t_lt_smax * ((int_s0 + self.s_max) / 2) #F, J,\n",
    "        d_at_smax = int_d_mag - d_lt_smax               #F, J,\n",
    "        t_at_smax = d_at_smax / self.s_max              #F, J,\n",
    "        t_tot = self.reax_t + t_lt_smax + t_at_smax     # F, J,\n",
    "\n",
    "        # subtract the arrival time (t_tot) from time of flight of ball\n",
    "        int_dT = self.T.view(1, 1, -1, 1) - t_tot.unsqueeze(2)         #F, T, J\n",
    "        #int_dT.register_hook(lambda x: print(x))\n",
    "        \n",
    "        # calculate interception probability for each player, field loc, time of flight (logistic function)\n",
    "        #p_int.register_hook(lambda x: print('before calculation', x))\n",
    "        #self.tti_sigma.register_hook(lambda x: print('tti_sigma before p_int', x.shape, x.mean()))\n",
    "        p_int = torch.sigmoid((3.14 / (1.732 * self.tti_sigma)) * int_dT) #F, T, J\n",
    "        #p_int.register_hook(lambda x: print('before tof ind', x.shape, (x != 0).sum(), x.sum()))\n",
    "        #self.tti_sigma.register_hook(lambda x: print('tti_sigma before tof', x))\n",
    "        if TUNING == TuningParam.sigma:\n",
    "            # get p_int for actual tof\n",
    "            tof = torch.round(frame[:, 0, -1] * 10).long().view(-1, 1, 1, 1).repeat(1, p_int.size(1), 1, p_int.size(-1))\n",
    "            p_int = torch.gather(p_int, 2, tof).squeeze() # F, J\n",
    "            #self.tti_sigma.register_hook(lambda x: print('tti_sigma before ball_field_ind', x))\n",
    "            #p_int.register_hook(lambda x: print('before ball_field_ind', x.shape, (x != 0).sum(), x.sum()))\n",
    "            # index into ball position\n",
    "            ball_end_x = frame[:, 0, -3].int()\n",
    "            ball_end_y = frame[:, 0, -2].int()\n",
    "            ball_end_np = np.array([ball_end_y.cpu().numpy()[0], ball_end_x.cpu().numpy()[0]]).astype(int)\n",
    "            ball_field_ind = (ball_end_y * self.x.shape[0] + ball_end_x).long().view(-1, 1, 1).repeat(1, 1, p_int.size(-1))\n",
    "            p_int = torch.gather(p_int, 1, ball_field_ind).squeeze()\n",
    "        #self.tti_sigma.register_hook(lambda x: print('tti_sigma loss grad', x))\n",
    "        #p_int.register_hook(lambda x: print('loss grad', x.shape, (x != 0).sum(), x.sum()))\n",
    "        \n",
    "        dx = reach_vecs[:, 0] #F\n",
    "        dy = reach_vecs[:, 1] #F\n",
    "        vx = dx[:, None]/T[None, :]   #F, T\n",
    "        vy = dy[:, None]/T[None, :]   #F, T\n",
    "        vz_0 = (self.T * self.g)/2    #T\n",
    "        \n",
    "        # note that idx (i, j, k) into below arrays is invalid when j < k\n",
    "        traj_ts = torch.tile(T, (len(field_locs), len(T), 1)) #(F, T, T)\n",
    "        traj_locs_x_idx = torch.round(torch.clip((ball_start[0]+vx.unsqueeze(-1)*T), 0, len(x)-1)).int() # F, T, T\n",
    "        traj_locs_y_idx = torch.round(torch.clip((ball_start[1]+vy.unsqueeze(-1)*T), 0, len(y)-1)).int() # F, T, T\n",
    "        traj_locs_z = 2.0+vz_0.view(1, -1, 1)*traj_ts-0.5*g*traj_ts*traj_ts #F, T, T\n",
    "        lambda_z = torch.where((traj_locs_z<self.z_max) & (traj_locs_z>self.z_min), 1, 0) #F, T, T\n",
    "        \n",
    "        path_idxs = (traj_locs_y_idx * self.x.shape[0] + traj_locs_x_idx).flatten()  # (F*T*T,)\n",
    "        # 10*traj_ts - 1 converts the times into indices - hacky\n",
    "        traj_t_idxs = torch.round(10*traj_ts - 1).flatten().int()  # (F*T*T,)\n",
    "        p_int_traj = p_int[path_idxs, traj_t_idxs]  # (F*T*T, J)\n",
    "        p_int_traj = p_int_traj.reshape((*traj_locs_x_idx.shape, len(reaction_player_locs)))\n",
    "        \n",
    "        path_idxs = np.ravel_multi_index(np.stack((traj_locs_y_idx, traj_locs_x_idx)).reshape(2, -1), xx.shape)  # (F*T*T,)\n",
    "        traj_t_idxs = np.rint(10*traj_ts - 1).flatten().astype(int)  # (F, T, T)\n",
    "        p_int_traj = p_int[path_idxs, traj_t_idxs]\\\n",
    "                        .reshape((*traj_locs_x_idx.shape, len(reaction_player_locs))) *\\\n",
    "                        lambda_z.unsqueeze(-1) # F, T, T, J\n",
    "        norm_factor = torch.maximum(1., p_int_traj.sum(dim=-1))  #F, T, T\n",
    "        p_int_traj_norm = (p_int_traj / norm_factor.unsqueeze(-1))  #F, T, T, J\n",
    "        \n",
    "        # independent int probs at each point on trajectory\n",
    "        all_p_int_traj = torch.sum(p_int_traj_norm, dim=-1)  # F, T, T\n",
    "        off_p_int_traj = torch.sum((player_teams == 1)[None,None,None] * p_int_traj_norm, dim=-1)\n",
    "        def_p_int_traj = torch.sum((player_teams == 0)[None,None,None] * p_int_traj_norm, dim=-1)\n",
    "        ind_p_int_traj = p_int_traj_norm #use for analyzing specific players\n",
    "        \n",
    "        # calc decaying residual probs after you take away p_int on earlier times in the traj \n",
    "        compl_all_p_int_traj = 1-all_p_int_traj  # F, T, T\n",
    "        remaining_compl_p_int_traj = torch.cumprod(compl_all_p_int_traj, dim=-1)  # F, T, T\n",
    "        # maximum 0 because if it goes negative the pass has been caught by then and theres no residual probability\n",
    "        shift_compl_cumsum = torch.roll(remaining_compl_p_int_traj, 1, dims=-1)  # F, T, T\n",
    "        shift_compl_cumsum[:, :, 0] = 1\n",
    "        \n",
    "        # multiply residual prob by p_int at that location and lambda\n",
    "        lambda_all = self.tti_lambda_off * player_teams + self.tti_lambda_def * (1 - player_teams)\n",
    "        off_completion_prob_dt = shift_compl_cumsum * off_p_int_traj * self.tti_lambda_off  # F, T, T\n",
    "        def_completion_prob_dt = shift_compl_cumsum * def_p_int_traj * self.tti_lambda_def  # F, T, T\n",
    "        all_completion_prob_dt = off_completion_prob_dt + def_completion_prob_dt\n",
    "        ind_completion_prob_dt = shift_compl_cumsum[:, :, :, None] * ind_p_int_traj * lambda_all[None,None,None]  # F, T, T, J\n",
    "        \n",
    "        # now accumulate values over total traj for each team and take at T=t\n",
    "        all_completion_prob = torch.cumsum(all_completion_prob_dt, dim=-1)  # F, T, T\n",
    "        off_completion_prob = torch.cumsum(off_completion_prob_dt, dim=-1)  # F, T, T\n",
    "        def_completion_prob = torch.cumsum(def_completion_prob_dt, dim=-1)  # F, T, T\n",
    "        ind_completion_prob = torch.cumsum(ind_completion_prob_dt, dim=-2)  # F, T, T, J\n",
    "        \n",
    "        # this einsum takes the diagonal values over the last two axes where T = t\n",
    "        # this takes care of the t > T issue.\n",
    "        all_p_int_pass = torch.einsum('ijj->ij', all_completion_prob)  # F, T\n",
    "        off_p_int_pass = torch.einsum('ijj->ij', off_completion_prob)  # F, T\n",
    "        def_p_int_pass = torch.einsum('ijj->ij', def_completion_prob)  # F, T\n",
    "        ind_p_int_pass = torch.einsum('ijjk->ijk', ind_completion_prob)  # F, T, J\n",
    "        no_p_int_pass = 1-all_p_int_pass #F, T\n",
    "\n",
    "        assert torch.allclose(all_p_int_pass, off_p_int_pass + def_p_int_pass, atol=0.01)\n",
    "        assert torch.allclose(all_p_int_pass, ind_p_int_pass.sum(-1), atol=0.01)\n",
    "        return off_p_int_pass, def_p_int_pass, ind_p_int_pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Dataset, Model and Run Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TUNING == TuningParam.sigma:\n",
    "    event_filter = 'pass_forward'\n",
    "elif TUNING == TuningParam.lamb:\n",
    "    event_filter = 'pass_arrived'\n",
    "ds = PlaysDataset(data_dir = '~/Downloads/nfl-big-data-bowl-2021/', all_weeks=False, event_filter=event_filter)\n",
    "loader = torch.utils.data.DataLoader(ds, batch_size=8, num_workers=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = ds[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from tqdm.notebook import tqdm\n",
    "model = CompProbModel(tti_sigma=0.8)\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "# check if we want cuda\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    loss_fn = loss_fn.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "total_loss = 0\n",
    "\n",
    "for epoch in range(1, 20):\n",
    "    prog_bar = loader#tqdm(loader)\n",
    "    total_loss = 0\n",
    "    for ind, (data, target) in enumerate(prog_bar):\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        \n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target.float())\n",
    "        total_loss = total_loss + loss.detach().cpu().item()\n",
    "\n",
    "        # step gradient\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        prog_bar.set_description(\"Batch %d Loss %.3f\" % (epoch, total_loss / (ind + 1)))\n",
    "        ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.tti_lambda_off\n",
    "model.tti_lambda_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.tti_sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load files\n",
    "data_dir = '../data/'\n",
    "tracking_df = pd.read_csv('../data/week1_norm.csv')\n",
    "plays_df = pd.read_csv('../data/plays.csv')\n",
    "\n",
    "#print(tracking_df.columns)\n",
    "\n",
    "# get valid frames for tuning from tracking df\n",
    "tracking_df = tracking_df[tracking_df['event'].isin(['pass_forward', 'pass_arrived', \n",
    "    'pass_outcome_caught', 'pass_outcome_incomplete', 'pass_outcome_touchdown', 'pass_outcome_intercepted'])]\n",
    "tracking_df['valid_frame'] = tracking_df['event'].str.contains('pass_forward')\n",
    "tracking_df = tracking_df.groupby(['playId', 'gameId']).filter(lambda l: l['valid_frame'].any()).reset_index()\n",
    "\n",
    "# merge tracking df and plays df\n",
    "all_plays = plays_df.merge(tracking_df, how='left', on=['playId', 'gameId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play = tracking_df[(tracking_df.playId == 81) & (tracking_df.gameId == 2018090902)]\n",
    "print(pd.to_timedelta(pd.to_datetime(play[play.event == 'pass_arrived'].time.iloc[0]) - pd.to_datetime(play[play.event == 'pass_forward'].time.iloc[0])).total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_df[tracking_df.position != 'QB'][['gameId', 'playId', 'nflId']].drop_duplicates().groupby(['gameId', 'playId']).nflId.count().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dist_off = min_dist_off.rename(columns={0:'ball_dist'})\n",
    "complete_passes = all_plays.loc[all_plays.event.isin(['pass_outcome_caught', 'pass_outcome_touchdown'])][['gameId', 'playId']]\n",
    "incomplete_passes = all_plays.loc[all_plays.event.isin(['pass_outcome_incomplete'])][['gameId', 'playId']]\n",
    "\n",
    "print(complete_passes.merge(min_dist_off).drop_duplicates().ball_dist.median())\n",
    "print(incomplete_passes.merge(min_dist_off).drop_duplicates().ball_dist.mean())\n",
    "\n",
    "min_dist_def = min_dist_def.rename(columns={0:'ball_dist'})\n",
    "complete_passes = all_plays.loc[all_plays.event.isin(['pass_outcome_caught', 'pass_outcome_touchdown'])][['gameId', 'playId']]\n",
    "incomplete_passes = all_plays.loc[all_plays.event.isin(['pass_outcome_incomplete'])][['gameId', 'playId']]\n",
    "\n",
    "print(complete_passes.merge(min_dist_def).drop_duplicates().ball_dist.mean())\n",
    "print(incomplete_passes.merge(min_dist_def).drop_duplicates().ball_dist.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_plays.loc[(all_plays.gameId == 2018090600) & (all_plays.playId == 146)][['displayName', 'x', 'y']]\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from visualize2 import AnimatePlay\n",
    "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n",
    "play_df = tracking_df[(tracking_df.gameId == 2018091000) & (tracking_df.playId == 3016)]\n",
    "\n",
    "animated_play = AnimatePlay(play_df, 20)#play_df[play_df.frameId <= 46], 20)\n",
    "HTML(animated_play.ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_nearest_player(play_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions to get nearest offensive and defensive players in grouped df\n",
    "def get_nearest_player(df):\n",
    "    df = df[df.event.isin(['pass_arrived'])]\n",
    "    if len(df) == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    ball_end = df[df.nflId == 0][['x', 'y']].head(1)\n",
    "    assert len(ball_end) == 1, print(len(ball_end))\n",
    "    \n",
    "    players_end = df[(df.nflId != 0) & (df.team_pos == 'OFF')][['x', 'y']]\n",
    "    min_dist = np.linalg.norm(players_end.values - ball_end.values, axis=1).min()\n",
    "    \n",
    "    return min_dist\n",
    "\n",
    "def get_nearest_player_off(df):\n",
    "    df = df[df.event.isin(['pass_arrived'])]\n",
    "    if len(df) == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    ball_end = df[df.nflId == 0][['x', 'y']].head(1)\n",
    "    assert len(ball_end) == 1, print(len(ball_end))\n",
    "    \n",
    "    players_end = df[(df.nflId != 0) & (df.team_pos == 'OFF')][['x', 'y']]\n",
    "    min_dist = np.linalg.norm(players_end.values - ball_end.values, axis=1).min()\n",
    "    \n",
    "    return min_dist\n",
    "\n",
    "def get_nearest_player_def(df):\n",
    "    df = df[df.event.isin(['pass_arrived'])]\n",
    "    if len(df) == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    ball_end = df[df.nflId == 0][['x', 'y']].head(1)\n",
    "    assert len(ball_end) == 1, print(len(ball_end))\n",
    "    \n",
    "    players_end = df[(df.nflId != 0) & (df.team_pos == 'DEF')][['x', 'y']]\n",
    "    min_dist = np.linalg.norm(players_end.values - ball_end.values, axis=1).min()\n",
    "    \n",
    "    return min_dist\n",
    "\n",
    "# get bal\n",
    "min_dist_off = all_plays.groupby(['playId', 'gameId']).apply(get_nearest_player_off).reset_index()\n",
    "min_dist_def = all_plays.groupby(['playId', 'gameId']).apply(get_nearest_player_def).reset_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
