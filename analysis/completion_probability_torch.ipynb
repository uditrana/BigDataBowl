{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 6 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import dask.dataframe as dd\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(nb_workers=6)\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions to get nearest offensive and defensive players in grouped df\n",
    "def get_nearest_player(df):\n",
    "    df = df[df.event.isin(['pass_arrived'])]\n",
    "    if len(df) == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    ball_end = df[df.nflId == 0][['x', 'y']].head(1)\n",
    "    assert len(ball_end) == 1, print(len(ball_end))\n",
    "    \n",
    "    players_end = df[(df.nflId != 0) & (df.team_pos == 'OFF')][['x', 'y']]\n",
    "    min_dist = np.linalg.norm(players_end.values - ball_end.values, axis=1).min()\n",
    "    \n",
    "    return min_dist\n",
    "\n",
    "def get_nearest_player_off(df):\n",
    "    df = df[df.event.isin(['pass_arrived'])]\n",
    "    if len(df) == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    ball_end = df[df.nflId == 0][['x', 'y']].head(1)\n",
    "    assert len(ball_end) == 1, print(len(ball_end))\n",
    "    \n",
    "    players_end = df[(df.nflId != 0) & (df.team_pos == 'OFF')][['x', 'y']]\n",
    "    min_dist = np.linalg.norm(players_end.values - ball_end.values, axis=1).min()\n",
    "    \n",
    "    return min_dist\n",
    "\n",
    "def get_nearest_player_def(df):\n",
    "    df = df[df.event.isin(['pass_arrived'])]\n",
    "    if len(df) == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    ball_end = df[df.nflId == 0][['x', 'y']].head(1)\n",
    "    assert len(ball_end) == 1, print(len(ball_end))\n",
    "    \n",
    "    players_end = df[(df.nflId != 0) & (df.team_pos == 'DEF')][['x', 'y']]\n",
    "    min_dist = np.linalg.norm(players_end.values - ball_end.values, axis=1).min()\n",
    "    \n",
    "    return min_dist\n",
    "\n",
    "# get bal\n",
    "min_dist_off = all_plays.groupby(['playId', 'gameId']).apply(get_nearest_player_off).reset_index()\n",
    "min_dist_def = all_plays.groupby(['playId', 'gameId']).apply(get_nearest_player_def).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plays Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlaysDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        # load csvs\n",
    "        tracking_df = pd.read_csv(os.path.join(data_dir, 'week1_norm.csv'))\n",
    "\n",
    "        # get valid frames for tuning from tracking df\n",
    "        #tracking_df = tracking_df[tracking_df['event'].isin(['pass_forward', 'pass_arrived', \n",
    "        #    'pass_outcome_caught', 'pass_outcome_incomplete', 'pass_outcome_touchdown', 'pass_outcome_intercepted'])]\n",
    "        self.play_list = tracking_df[tracking_df['event'] == 'pass_arrived'][['gameId', 'playId']].drop_duplicates()\n",
    "        tracking_df = self.play_list.merge(tracking_df, on=['gameId', 'playId'])\n",
    "        \n",
    "        # calculate ball ending position\n",
    "        ball_end = tracking_df[(tracking_df.nflId == 0) & (tracking_df.event == 'pass_arrived')][['gameId', 'playId', 'x', 'y']]\n",
    "        ball_end = ball_end.rename(columns={'x': 'ball_x', 'y': 'ball_y'})\n",
    "        \n",
    "        # merge tracking_df with ball_end\n",
    "        tracking_df = tracking_df[tracking_df.nflId != 0].merge(ball_end, on=['gameId', 'playId'])\n",
    "                \n",
    "        # for each player, label whether they reached the ball (radius of 1.5 yds)\n",
    "        self.player_reached = tracking_df[tracking_df.event == 'pass_arrived'][['gameId', 'playId', 'nflId', 'x', 'y', 'ball_x', 'ball_y']]\n",
    "        self.player_reached['close_to_ball'] = np.less_equal(np.linalg.norm(np.stack([self.player_reached.x.values,\n",
    "                    self.player_reached.y.values], axis=-1) - np.stack([self.player_reached.ball_x.values,\n",
    "                    self.player_reached.ball_y.values], axis=-1), axis=1), 1.5).astype(int)\n",
    "        \n",
    "        # only keep frame when ball is passed\n",
    "        self.all_plays = tracking_df[tracking_df.event == 'pass_forward']\n",
    "        \n",
    "        # turn play list into np array\n",
    "        self.play_list = self.play_list.values\n",
    "        \n",
    "        # max number of players per play\n",
    "        self.max_num = 17\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.play_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        gameId, playId = self.play_list[idx]\n",
    "        frame = self.all_plays[(self.all_plays.gameId == gameId) & (self.all_plays.playId == playId)]\n",
    "        sigma_label = self.player_reached[(self.all_plays.gameId == gameId) & (self.all_plays.playId == playId)][['nflId', 'close_to_ball']]\n",
    "\n",
    "        # calculate important metrics in frame\n",
    "        ball_end = torch.tensor(frame[(frame.nflId == 0) & (frame.event == 'pass_arrived')][['x', 'y']].head(1))\n",
    "\n",
    "        ball_end = torch.tensor(frame.loc[frame.position == 'QB'][['x', \n",
    "                'y']].iloc[0].round().values)\n",
    "        \n",
    "        # clean up frame\n",
    "        frame = frame.loc[frame.position != 'QB'].merge(sigma_label, on='nflId')\n",
    "        frame = frame.replace('OFF', 1)\n",
    "        frame = frame.replace('DEF', 0)\n",
    "        frame['tof'] = pd.to_timedelta(pd.to_datetime(frame[frame.event == 'pass_arrived'].time.iloc[0]) - pd.to_datetime(frame[frame.event == 'pass_forward'].time.iloc[0])).total_seconds()\n",
    "        \n",
    "        # generate data, label, fill missing data\n",
    "        data = torch.tensor(frame[['nflId', 'x', 'y', 'v_x', 'v_y', 'a_x', 'a_y', 'team_pos', 'ball_x', 'ball_y', 'tof']].values).float()\n",
    "        label = torch.tensor(frame['close_to_ball'].values)\n",
    "        if data.size(0) < 17:\n",
    "            data = torch.vstack([data, torch.ones[17 - data.size(0), data.size(1)]])\n",
    "            label = torch.vstack([label, torch.zeros[17 - label.size(0)]])\n",
    "        \n",
    "        return data, label.long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completion Probability Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompProbModel(torch.nn.Module):\n",
    "    def __init__(self, a_max=7, s_max=9, avg_ball_speed=20, tti_sigma=0.5, tti_lambda=1.0):\n",
    "        # define parameters and whether or not to optimize\n",
    "        self.a_max = Variable(torch.tensor([a_max]), requires_grad=False)\n",
    "        self.s_max = Variable(torch.tensor([s_max]), requires_grad=False)\n",
    "        self.avg_ball_speed = Variable(torch.tensor([avg_ball_speed]), requires_grad=False)\n",
    "        self.tti_sigma = Variable(torch.tensor([tti_sigma.astype(torch.float32)]), requires_grad=True)\n",
    "        self.tti_lambda = Variable(torch.tensor([tti_lambda.astype(torch.float32)]), requires_grad=True)\n",
    "        self.reax_t = self.s_max / self.a_max\n",
    "        \n",
    "        # define field grid\n",
    "        x = torch.linspace(0.5, 119.5, 120)\n",
    "        y = torch.linspace(-0.5, 53.5, 55)\n",
    "        y[0] = -0.2\n",
    "        xx, yy = torch.meshgrid(x, y)\n",
    "        self.field_locs = torch.flatten(torch.stack((xx, yy), dim=-1), end_dim=-2)  # (F, 2)\n",
    "        self.T = torch.linspace(0.1, 4, 40) # (T,)\n",
    "    \n",
    "    def forward(self, frame):\n",
    "        v_x_r = frame[:, 5] * self.reax_t + frame[:, 3]\n",
    "        v_y_r = frame.[:, 6] * self.reax_t + frame[:, 4]\n",
    "        v_r_mag = torch.norm(torch.tensor([v_x_r, v_y_r]), dim=0)\n",
    "        v_r_theta = torch.arctan(v_y_r / v_x_r).nan_to_num()\n",
    "\n",
    "        x_r = frame[:, 1] + frame[:, 3] * self.reax_t + 0.5 * frame[:, 5] * self.reax_t**2\n",
    "        y_r = frame[:, 2] + frame[:, 4] * self.reax_t + 0.5 * frame[:, 6] * self.reax_t**2\n",
    "        \n",
    "        # get each player's team, location, and velocity\n",
    "        player_teams = frame[:, -1] # J,\n",
    "        reaction_player_locs = torch.stack([x_r, y_r]).int() # (J, 2)\n",
    "        reaction_player_vels = torch.stack([v_x_r, v_y_r], dim=-1) #(J,2)\n",
    "        \n",
    "        # calculate each player's distance from each field location\n",
    "        int_d_vec = self.field_locs.unsqueeze(1) - reaction_player_locs #F, J, 2\n",
    "        int_d_mag = torch.norm(int_d_vec, dim=2) # F, J\n",
    "        \n",
    "        # take dot product of velocity and direction\n",
    "        int_s0 = torch.clip(torch.sum(int_d_vec * reaction_player_vels, dim=2) / int_d_mag, -1 * self.s_max, self.s_max) #F, J\n",
    "\n",
    "        # calculate time it takes for each player to reach each field position accounting for their current velocity and acceleration\n",
    "        t_lt_smax = (self.s_max - int_s0) / self.a_max  #F, J,\n",
    "        d_lt_smax = t_lt_smax * ((int_s0 + self.s_max) / 2) #F, J,\n",
    "        d_at_smax = int_d_mag - d_lt_smax               #F, J,\n",
    "        t_at_smax = d_at_smax / self.s_max              #F, J,\n",
    "        t_tot = t_lt_smax + t_at_smax                     #F, J,\n",
    "\n",
    "        # subtract the arrival time (t_tot) from time of flight of ball\n",
    "        int_dT = self.T.view(1, -1, 1) - t_tot.unsqueeze(1)         #F, T, J\n",
    "        \n",
    "        # calculate interception probability for each player, field loc, time of flight (logistic function)\n",
    "        p_int = 1 / (1. + torch.exp(-1 * torch.pi / torch.sqrt(3.0) / self.tti_sigma * int_dT)) #F, T, J\n",
    "        \n",
    "        # get p_int for actual tof\n",
    "        tof = torch.round(frame[:, -1] * 10)\n",
    "        p_int = p_int[:, tof, :] # F, J\n",
    "        \n",
    "        # index into ball position\n",
    "        ball_end_x = data[:, -3]\n",
    "        ball_end_y = data[:, -2]\n",
    "        ball_field_ind = self.field_locs[:, 0] == \n",
    "\n",
    "        p_int = p_int[, :]\n",
    "        \n",
    "        return p_int\n",
    "        \n",
    "        # TODO(adit98) change this\n",
    "        #lambda_z = torch.where((traj_locs_z<3) & (traj_locs_z>0), 1, 0) #F, T, T\n",
    "        # apply lambda\n",
    "        # probs = probs * lambda_z.unsqueeze(-1) * lambda_dt\n",
    "        # norm_factor = torch.maximum(1., probs.sum(dim=-1))  #F, T, T\n",
    "        # probs_norm = (probs / norm_factor[..., None])  #F, T, T, J\n",
    "        \n",
    "        # check if this is valid\n",
    "\n",
    "        # compute reach vecs (path of ball)\n",
    "        #reach_vecs = ball_start - field_locs  # (F, 2)\n",
    "        \n",
    "        # invert direction signs\n",
    "        #dx = -1 * reach_vecs[:, 0]\n",
    "        #dy = -1 * reach_vecs[:, 1]\n",
    "\n",
    "        # calculate ball velocity for each possible time of flight (0 to 4)\n",
    "        #vx = dx.unsqueeze(-1) / T.unsqueeze(0)\n",
    "        #vy = dy.unsqueeze(-1) / T.unsqueeze(0)\n",
    "        #g = 10.72468 # gravitation constant (yards/s^2)\n",
    "        #vz_0 = (T * g) / 2\n",
    "\n",
    "        # calculate every (x, y, z) location that ball passes through\n",
    "        # note that idx (i, j, k) into below arrays is invalid when j < k\n",
    "        #traj_ts = torch.tile(T, (len(field_locs), len(T), 1)) #(F, T, T)\n",
    "        #traj_locs_x_idx = torch.round(torch.clip((ball_start[0]+vx.unsqueeze(-1)*T), 0, len(x)-1)) # F, T, T\n",
    "        #traj_locs_y_idx = torch.round(torch.clip((ball_start[1]+vy.unsqueeze(-1)*T), 0, len(y)-1)) # F, T, T\n",
    "        #traj_locs_z = 2.0+vz_0.view(1, -1, 1)*traj_ts-0.5*g*traj_ts*traj_ts #F, T, T\n",
    "        \n",
    "        # TODO(adit98) fix this\n",
    "        #path_idxs = torch.ravel_multi_index(torch.stack((traj_locs_y_idx, traj_locs_x_idx)).reshape(2, -1), xx.shape)  # (F*T*T,)\n",
    "        #traj_t_idxs = torch.round(10*traj_ts - 1).flatten()  # (F, T, T)\n",
    "        #probs = p_int[path_idxs, t] # F*T*T, J\n",
    "        #probs = probs.reshape((*traj_locs_x_idx.shape, len(reaction_player_locs)))  # F, T, T, J\n",
    "        \n",
    "        # TODO(adit98) this is where to add lambda tuning\n",
    "        #lambda_dt = 1\n",
    "        #probs = probs * lambda_z.unsqueeze(-1) * lambda_dt\n",
    "        #norm_factor = torch.maximum(1., probs.sum(dim=-1))  #F, T, T\n",
    "        #probs_norm = (probs / norm_factor[..., None])  #F, T, T, J\n",
    "\n",
    "        #total_probs = torch.sum(probs_norm, dim=-1)  # F, T, T\n",
    "        #compl_total_probs = 1 - total_probs  # F, T, T\n",
    "        #remaining_compl_probs = torch.cumprod(compl_total_probs, dim=-1)  # F, T, T\n",
    "        #off_probs = torch.sum(probs_norm * player_teams, dim=-1)\n",
    "        #def_probs = torch.sum(probs_norm * (1 - player_teams), dim=-1)\n",
    "\n",
    "        # maximum 0 because if it goes negative the pass has been caught by then and theres no residual probability\n",
    "\n",
    "        #shift_compl_cumsum = torch.roll(remaining_compl_probs, 1, dim=-1)  # F, T, T\n",
    "        #shift_compl_cumsum[:, :, 0] = 1\n",
    "        #total_completion_prob_dt = shift_compl_cumsum * total_probs  # F, T, T\n",
    "        #total_completion_prob = torch.cumsum(total_completion_prob_dt, dim=-1)  # F, T, T\n",
    "\n",
    "        #completion_prob_off_dt = shift_compl_cumsum * off_probs  # F, T, T\n",
    "        #completion_prob_def_dt = shift_compl_cumsum * def_probs  # F, T, T\n",
    "        #completion_prob_off = torch.cumsum(completion_prob_off_dt, dim=-1)  # F, T, T\n",
    "        #completion_prob_def = torch.cumsum(completion_prob_def_dt, dim=-1)  # F, T, T\n",
    "        \n",
    "        # this einsum takes the diagonal values over the last two axes\n",
    "        # where T = t. this takes care of the t > T issue.\n",
    "        #throw_p_int_off = torch.einsum('ijj->ij', total_completion_prob_off)  # F, T\n",
    "        #throw_p_int_def = torch.einsum('ijj->ij', total_completion_prob_def)  # F, T\n",
    "        #throw_p_int = torch.einsum('ijj->ij', total_completion_prob)  # F, T\n",
    "        \n",
    "        # below gets cutoff for combined model\n",
    "        #field_p_int_off = throw_p_int_off.mean(dim=1)  # F,\n",
    "        #field_p_int_def = throw_p_int_def.mean(dim=1)  # F,\n",
    "        #field_p_int = throw_p_int.mean(dim=1)  # F,\n",
    "\n",
    "        #field_p_no_int = 1-field_p_int\n",
    "\n",
    "        #field_df = pd.DataFrame({\n",
    "        #    'ball_start_x': ball_start[0],\n",
    "        #    'ball_start_y': ball_start[1], \n",
    "        #    'ball_end_x': field_locs[:,0],\n",
    "        #    'ball_end_y': field_locs[:,1],\n",
    "        #    'p_mass_1': (((field_p_int_off-field_p_int_def)+1.)/2.).round(3),\n",
    "        #    'p_mass_2': field_p_no_int.round(3),\n",
    "            # 'p_mass_players': p_int_norm,\n",
    "        #})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Dataset, Model and Run Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(779, 2)\n",
      "torch.Size([12, 7])\n"
     ]
    }
   ],
   "source": [
    "ds = PlaysDataset(data_dir = '../data/')\n",
    "print(ds[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['gameId', 'playId', 'frameId', 'event', 'nflId', 'displayName',\n",
      "       'jerseyNumber', 'position', 'position_general', 'team', 'team_pos',\n",
      "       'teamAbbr', 'route', 'time', 'los', 'x', 'y', 'dis', 'o', 's', 's_dir',\n",
      "       's_dir_rad', 'v_x', 'v_y', 'v_theta', 'v_mag', 'a_old', 'a_x', 'a_y',\n",
      "       'a_theta', 'a_mag'],\n",
      "      dtype='object')\n",
      "2018-09-09T17:04:04.500Z\n"
     ]
    }
   ],
   "source": [
    "# load files\n",
    "data_dir = '../data/'\n",
    "tracking_df = pd.read_csv('../data/week1_norm.csv')\n",
    "plays_df = pd.read_csv('../data/plays.csv')\n",
    "\n",
    "#print(tracking_df.columns)\n",
    "\n",
    "# get valid frames for tuning from tracking df\n",
    "tracking_df = tracking_df[tracking_df['event'].isin(['pass_forward', 'pass_arrived', \n",
    "    'pass_outcome_caught', 'pass_outcome_incomplete', 'pass_outcome_touchdown', 'pass_outcome_intercepted'])]\n",
    "tracking_df['valid_frame'] = tracking_df['event'].str.contains('pass_forward')\n",
    "tracking_df = tracking_df.groupby(['playId', 'gameId']).filter(lambda l: l['valid_frame'].any()).reset_index()\n",
    "\n",
    "# merge tracking df and plays df\n",
    "all_plays = plays_df.merge(tracking_df, how='left', on=['playId', 'gameId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-09 17:04:03+00:00\n",
      "2018-09-09 17:04:04.500000+00:00\n",
      "1.5\n"
     ]
    }
   ],
   "source": [
    "play = tracking_df[(tracking_df.playId == 81) & (tracking_df.gameId == 2018090902)]\n",
    "print(pd.to_timedelta(pd.to_datetime(play[play.event == 'pass_arrived'].time.iloc[0]) - pd.to_datetime(play[play.event == 'pass_forward'].time.iloc[0])).total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracking_df[tracking_df.position != 'QB'][['gameId', 'playId', 'nflId']].drop_duplicates().groupby(['gameId', 'playId']).nflId.count().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.085102305866526\n",
      "1.6439466513218899\n",
      "4.790180627434475\n",
      "2.435306899869004\n"
     ]
    }
   ],
   "source": [
    "min_dist_off = min_dist_off.rename(columns={0:'ball_dist'})\n",
    "complete_passes = all_plays.loc[all_plays.event.isin(['pass_outcome_caught', 'pass_outcome_touchdown'])][['gameId', 'playId']]\n",
    "incomplete_passes = all_plays.loc[all_plays.event.isin(['pass_outcome_incomplete'])][['gameId', 'playId']]\n",
    "\n",
    "print(complete_passes.merge(min_dist_off).drop_duplicates().ball_dist.median())\n",
    "print(incomplete_passes.merge(min_dist_off).drop_duplicates().ball_dist.mean())\n",
    "\n",
    "min_dist_def = min_dist_def.rename(columns={0:'ball_dist'})\n",
    "complete_passes = all_plays.loc[all_plays.event.isin(['pass_outcome_caught', 'pass_outcome_touchdown'])][['gameId', 'playId']]\n",
    "incomplete_passes = all_plays.loc[all_plays.event.isin(['pass_outcome_incomplete'])][['gameId', 'playId']]\n",
    "\n",
    "print(complete_passes.merge(min_dist_def).drop_duplicates().ball_dist.mean())\n",
    "print(incomplete_passes.merge(min_dist_def).drop_duplicates().ball_dist.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_plays.loc[(all_plays.gameId == 2018090600) & (all_plays.playId == 146)][['displayName', 'x', 'y']]\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from visualize2 import AnimatePlay\n",
    "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n",
    "play_df = tracking_df[(tracking_df.gameId == 2018091000) & (tracking_df.playId == 3016)]\n",
    "\n",
    "animated_play = AnimatePlay(play_df, 20)#play_df[play_df.frameId <= 46], 20)\n",
    "HTML(animated_play.ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_nearest_player(play_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
