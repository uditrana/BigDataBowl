{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 6 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import dask.dataframe as dd\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(nb_workers=6)\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_plays' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ab63c4fc2601>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# get bal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mmin_dist_off\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_plays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'playId'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gameId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_nearest_player_off\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0mmin_dist_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_plays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'playId'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gameId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_nearest_player_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_plays' is not defined"
     ]
    }
   ],
   "source": [
    "# helper functions to get nearest offensive and defensive players in grouped df\n",
    "def get_nearest_player(df):\n",
    "    df = df[df.event.isin(['pass_arrived'])]\n",
    "    if len(df) == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    ball_end = df[df.nflId == 0][['x', 'y']].head(1)\n",
    "    assert len(ball_end) == 1, print(len(ball_end))\n",
    "    \n",
    "    players_end = df[(df.nflId != 0) & (df.team_pos == 'OFF')][['x', 'y']]\n",
    "    min_dist = np.linalg.norm(players_end.values - ball_end.values, axis=1).min()\n",
    "    \n",
    "    return min_dist\n",
    "\n",
    "def get_nearest_player_off(df):\n",
    "    df = df[df.event.isin(['pass_arrived'])]\n",
    "    if len(df) == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    ball_end = df[df.nflId == 0][['x', 'y']].head(1)\n",
    "    assert len(ball_end) == 1, print(len(ball_end))\n",
    "    \n",
    "    players_end = df[(df.nflId != 0) & (df.team_pos == 'OFF')][['x', 'y']]\n",
    "    min_dist = np.linalg.norm(players_end.values - ball_end.values, axis=1).min()\n",
    "    \n",
    "    return min_dist\n",
    "\n",
    "def get_nearest_player_def(df):\n",
    "    df = df[df.event.isin(['pass_arrived'])]\n",
    "    if len(df) == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    ball_end = df[df.nflId == 0][['x', 'y']].head(1)\n",
    "    assert len(ball_end) == 1, print(len(ball_end))\n",
    "    \n",
    "    players_end = df[(df.nflId != 0) & (df.team_pos == 'DEF')][['x', 'y']]\n",
    "    min_dist = np.linalg.norm(players_end.values - ball_end.values, axis=1).min()\n",
    "    \n",
    "    return min_dist\n",
    "\n",
    "# get bal\n",
    "min_dist_off = all_plays.groupby(['playId', 'gameId']).apply(get_nearest_player_off).reset_index()\n",
    "min_dist_def = all_plays.groupby(['playId', 'gameId']).apply(get_nearest_player_def).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plays Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlaysDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_dir, all_weeks=False):\n",
    "        if all_weeks:\n",
    "            all_data = []\n",
    "            for week in range(1, 18):\n",
    "                all_data.append(pd.read_csv(os.path.join(data_dir, 'week%d_norm.csv' % week)))\n",
    "                \n",
    "            tracking_df = pd.concat(all_data)\n",
    "            \n",
    "        else:\n",
    "            # load csvs\n",
    "            tracking_df = pd.read_csv(os.path.join(data_dir, 'week1_norm.csv'))\n",
    "\n",
    "        # get valid frames for tuning from tracking df (consider every pass, labels are 1 if there is a player close by)\n",
    "        #tracking_df = tracking_df[tracking_df['event'].isin(['pass_forward', 'pass_arrived', \n",
    "        #    'pass_outcome_caught', 'pass_outcome_incomplete', 'pass_outcome_touchdown', 'pass_outcome_intercepted'])]\n",
    "        pass_forward_plays = tracking_df[tracking_df['event'] == 'pass_forward'][['gameId', 'playId']].drop_duplicates()\n",
    "        pass_attempted_plays = tracking_df[tracking_df['event'] == 'pass_arrived'][['gameId', 'playId']].drop_duplicates()\n",
    "        tracking_df = pass_forward_plays.merge(pass_attempted_plays.merge(tracking_df, on=['gameId', 'playId']), on=['gameId', 'playId'])\n",
    "        \n",
    "        # calculate ball ending position\n",
    "        ball_end = tracking_df[(tracking_df.nflId == 0) & (tracking_df.event == 'pass_arrived')][['gameId', 'playId', 'x', 'y']]\n",
    "        ball_end = ball_end.rename(columns={'x': 'ball_x', 'y': 'ball_y'})\n",
    "\n",
    "        # remove plays where ball is thrown out of bounds\n",
    "        ball_end = ball_end[(ball_end.ball_x <= 119.5) & (ball_end.ball_x >= 0.5) & (ball_end.ball_y <= 53.5) & (ball_end.ball_y >= -0.5)]\n",
    "        \n",
    "        # merge tracking_df with ball_end\n",
    "        tracking_df = tracking_df[tracking_df.nflId != 0].merge(ball_end, on=['gameId', 'playId'])\n",
    "                \n",
    "        # for each player, label whether they reached the ball (radius of 1.5 yds)\n",
    "        self.player_reached = tracking_df[tracking_df.event == 'pass_arrived'][['gameId', 'playId', 'nflId', 'x', 'y', 'ball_x', 'ball_y']]\n",
    "        self.player_reached['close_to_ball'] = np.less_equal(np.linalg.norm(np.stack([self.player_reached.x.values,\n",
    "                    self.player_reached.y.values], axis=-1) - np.stack([self.player_reached.ball_x.values,\n",
    "                    self.player_reached.ball_y.values], axis=-1), axis=1), 1.5).astype(int)\n",
    "        \n",
    "        # store tracking_df\n",
    "        self.all_plays = tracking_df\n",
    "        \n",
    "        # turn play list into np array\n",
    "        self.play_list = tracking_df[['gameId', 'playId']].drop_duplicates().values\n",
    "        \n",
    "        # max number of players per play\n",
    "        self.max_num = 17\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.play_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        gameId = self.play_list[idx, 0]\n",
    "        playId = self.play_list[idx, 1]\n",
    "        \n",
    "        # load frame, sigma_label, and ball_end\n",
    "        frame = self.all_plays[(self.all_plays.gameId == gameId) & (self.all_plays.playId == playId)]\n",
    "        sigma_label = self.player_reached[(self.player_reached.gameId == gameId) & (self.player_reached.playId == playId)][['nflId', 'close_to_ball']]\n",
    "        \n",
    "        try:\n",
    "            ball_end = self.player_reached[(self.player_reached.gameId == gameId) & (self.player_reached.playId == playId)][['ball_x', 'ball_y']].iloc[0].values\n",
    "        except IndexError:\n",
    "            print(self.player_reached[(self.player_reached.gameId == gameId) & (self.player_reached.playId == playId)])\n",
    "            raise IndexError\n",
    "        # clean up frame (remove QB, merge with sigma_label, ball_end, remove pass_arrived event)\n",
    "        frame = frame.loc[frame.position != 'QB'].merge(sigma_label, on='nflId')\n",
    "        frame = frame.replace('OFF', 1)\n",
    "        frame = frame.replace('DEF', 0)\n",
    "        try:\n",
    "            frame['tof'] = pd.to_timedelta(pd.to_datetime(frame[frame.event == 'pass_arrived'].time.iloc[0]) - pd.to_datetime(frame[frame.event == 'pass_forward'].time.iloc[0])).total_seconds()\n",
    "        except IndexError:\n",
    "            print(frame[frame.event == 'pass_arrived'])\n",
    "            print(frame[frame.event == 'pass_forward'])\n",
    "            raise IndexError\n",
    "        frame['ball_x'] = ball_end[0]\n",
    "        frame['ball_y'] = ball_end[1]\n",
    "        frame = frame[frame.event == 'pass_forward']\n",
    "\n",
    "        # generate data, label, fill missing data\n",
    "        data = torch.tensor(frame[['nflId', 'x', 'y', 'v_x', 'v_y', 'a_x', 'a_y', 'team_pos', 'ball_x', 'ball_y', 'tof']].values).float()\n",
    "        label = torch.tensor(frame['close_to_ball'].values)\n",
    "        if data.size(0) < self.max_num:\n",
    "            data = torch.cat([data, torch.ones([self.max_num - data.size(0), data.size(1)])], dim=0)\n",
    "            label = torch.cat([label, torch.zeros([self.max_num - label.size(0)])], dim=0)\n",
    "        \n",
    "        return data, label.long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completion Probability Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompProbModel(torch.nn.Module):\n",
    "    def __init__(self, a_max=7, s_max=9, avg_ball_speed=20, tti_sigma=0.5, tti_lambda=1.0):\n",
    "        super().__init__()\n",
    "        \n",
    "        # define parameters and whether or not to optimize\n",
    "        self.a_max = Parameter(torch.tensor([a_max]), requires_grad=False).float()\n",
    "        self.s_max = Parameter(torch.tensor([s_max]), requires_grad=False).float()\n",
    "        self.avg_ball_speed = Parameter(torch.tensor([avg_ball_speed]), requires_grad=False).float()\n",
    "        self.tti_sigma = Parameter(torch.tensor([tti_sigma]), requires_grad=True).float()\n",
    "        self.tti_lambda = Parameter(torch.tensor([tti_lambda]), requires_grad=False).float()\n",
    "        self.reax_t = self.s_max / self.a_max\n",
    "\n",
    "        \n",
    "        # define field grid\n",
    "        self.x = torch.linspace(0.5, 119.5, 120)\n",
    "        self.y = torch.linspace(-0.5, 53.5, 55)\n",
    "        self.y[0] = -0.2\n",
    "        xx, yy = torch.meshgrid(self.x, self.y)\n",
    "        self.field_locs = Parameter(torch.flatten(torch.stack((xx, yy), dim=-1), end_dim=-2), requires_grad=False)  # (F, 2)\n",
    "        self.T = Parameter(torch.linspace(0.1, 4, 40), requires_grad=False) # (T,)\n",
    "    \n",
    "    def forward(self, frame):\n",
    "        v_x_r = frame[:, :, 5] * self.reax_t + frame[:, :, 3]\n",
    "        v_y_r = frame[:, :, 6] * self.reax_t + frame[:, :, 4]\n",
    "        v_r_mag = torch.norm(torch.stack([v_x_r, v_y_r], dim=-1), dim=-1)\n",
    "        v_r_theta = torch.arctan(v_y_r / v_x_r)\n",
    "        # fill nan\n",
    "        v_r_theta[v_r_theta != v_r_theta] = 0\n",
    "\n",
    "        x_r = frame[:, :, 1] + frame[:, :, 3] * self.reax_t + 0.5 * frame[:, :, 5] * self.reax_t**2\n",
    "        y_r = frame[:, :, 2] + frame[:, :, 4] * self.reax_t + 0.5 * frame[:, :, 6] * self.reax_t**2\n",
    "        \n",
    "        # get each player's team, location, and velocity\n",
    "        #player_teams = frame[:, :, -1] # J,\n",
    "        reaction_player_locs = torch.stack([x_r, y_r], dim=-1).int() # (J, 2)\n",
    "        reaction_player_vels = torch.stack([v_x_r, v_y_r], dim=-1) #(J, 2)\n",
    "        \n",
    "        # calculate each player's distance from each field location\n",
    "        int_d_vec = self.field_locs.unsqueeze(1).unsqueeze(0) - reaction_player_locs.unsqueeze(1) #F, J, 2\n",
    "        int_d_mag = torch.norm(int_d_vec, dim=-1) # F, J\n",
    "        \n",
    "        # take dot product of velocity and direction\n",
    "        int_s0 = torch.clip(torch.sum(int_d_vec * reaction_player_vels.unsqueeze(1), dim=-1) / int_d_mag, -1 * self.s_max.item(), self.s_max.item()) #F, J\n",
    "        #int_s0 = torch.sum(int_d_vec * reaction_player_vels.unsqueeze(1), dim=-1) / int_d_mag\n",
    "        \n",
    "        # calculate time it takes for each player to reach each field position accounting for their current velocity and acceleration\n",
    "        t_lt_smax = (self.s_max - int_s0) / self.a_max  #F, J,\n",
    "        d_lt_smax = t_lt_smax * ((int_s0 + self.s_max) / 2) #F, J,\n",
    "        d_at_smax = int_d_mag - d_lt_smax               #F, J,\n",
    "        t_at_smax = d_at_smax / self.s_max              #F, J,\n",
    "        t_tot = self.reax_t + t_lt_smax + t_at_smax     # F, J,\n",
    "\n",
    "        # subtract the arrival time (t_tot) from time of flight of ball\n",
    "        int_dT = self.T.view(1, 1, -1, 1) - t_tot.unsqueeze(2)         #F, T, J\n",
    "        #int_dT.register_hook(lambda x: print(x))\n",
    "        \n",
    "        # calculate interception probability for each player, field loc, time of flight (logistic function)\n",
    "        #p_int.register_hook(lambda x: print('before calculation', x))\n",
    "        #self.tti_sigma.register_hook(lambda x: print('tti_sigma before p_int', x.shape, x.mean()))\n",
    "        p_int = torch.sigmoid((3.14 / (1.732 * self.tti_sigma)) * int_dT) #F, T, J\n",
    "        #p_int.register_hook(lambda x: print('before tof ind', x.shape, (x != 0).sum(), x.sum()))\n",
    "        #self.tti_sigma.register_hook(lambda x: print('tti_sigma before tof', x))\n",
    "\n",
    "        # get p_int for actual tof\n",
    "        tof = torch.round(frame[:, 0, -1] * 10).long().view(-1, 1, 1, 1).repeat(1, p_int.size(1), 1, p_int.size(-1))\n",
    "        p_int = torch.gather(p_int, 2, tof).squeeze() # F, J\n",
    "        #self.tti_sigma.register_hook(lambda x: print('tti_sigma before ball_field_ind', x))\n",
    "        #p_int.register_hook(lambda x: print('before ball_field_ind', x.shape, (x != 0).sum(), x.sum()))\n",
    "\n",
    "        # index into ball position\n",
    "        ball_end_x = frame[:, 0, -3].int()\n",
    "        ball_end_y = frame[:, 0, -2].int()\n",
    "        ball_field_ind = (ball_end_y * self.x.shape[0] + ball_end_x).long().view(-1, 1, 1).repeat(1, 1, p_int.size(-1))\n",
    "        \n",
    "        p_int = torch.gather(p_int, 1, ball_field_ind).squeeze()\n",
    "        #self.tti_sigma.register_hook(lambda x: print('tti_sigma loss grad', x))\n",
    "        #p_int.register_hook(lambda x: print('loss grad', x.shape, (x != 0).sum(), x.sum()))\n",
    "\n",
    "\n",
    "        return p_int\n",
    "        \n",
    "        # TODO(adit98) change this\n",
    "        #lambda_z = torch.where((traj_locs_z<3) & (traj_locs_z>0), 1, 0) #F, T, T\n",
    "        # apply lambda\n",
    "        # probs = probs * lambda_z.unsqueeze(-1) * lambda_dt\n",
    "        # norm_factor = torch.maximum(1., probs.sum(dim=-1))  #F, T, T\n",
    "        # probs_norm = (probs / norm_factor[..., None])  #F, T, T, J\n",
    "        \n",
    "        # check if this is valid\n",
    "\n",
    "        # compute reach vecs (path of ball)\n",
    "        #reach_vecs = ball_start - field_locs  # (F, 2)\n",
    "        \n",
    "        # invert direction signs\n",
    "        #dx = -1 * reach_vecs[:, 0]\n",
    "        #dy = -1 * reach_vecs[:, 1]\n",
    "\n",
    "        # calculate ball velocity for each possible time of flight (0 to 4)\n",
    "        #vx = dx.unsqueeze(-1) / T.unsqueeze(0)\n",
    "        #vy = dy.unsqueeze(-1) / T.unsqueeze(0)\n",
    "        #g = 10.72468 # gravitation constant (yards/s^2)\n",
    "        #vz_0 = (T * g) / 2\n",
    "\n",
    "        # calculate every (x, y, z) location that ball passes through\n",
    "        # note that idx (i, j, k) into below arrays is invalid when j < k\n",
    "        #traj_ts = torch.tile(T, (len(field_locs), len(T), 1)) #(F, T, T)\n",
    "        #traj_locs_x_idx = torch.round(torch.clip((ball_start[0]+vx.unsqueeze(-1)*T), 0, len(x)-1)) # F, T, T\n",
    "        #traj_locs_y_idx = torch.round(torch.clip((ball_start[1]+vy.unsqueeze(-1)*T), 0, len(y)-1)) # F, T, T\n",
    "        #traj_locs_z = 2.0+vz_0.view(1, -1, 1)*traj_ts-0.5*g*traj_ts*traj_ts #F, T, T\n",
    "        \n",
    "        # TODO(adit98) fix this\n",
    "        #path_idxs = torch.ravel_multi_index(torch.stack((traj_locs_y_idx, traj_locs_x_idx)).reshape(2, -1), xx.shape)  # (F*T*T,)\n",
    "        #traj_t_idxs = torch.round(10*traj_ts - 1).flatten()  # (F, T, T)\n",
    "        #probs = p_int[path_idxs, t] # F*T*T, J\n",
    "        #probs = probs.reshape((*traj_locs_x_idx.shape, len(reaction_player_locs)))  # F, T, T, J\n",
    "        \n",
    "        # TODO(adit98) this is where to add lambda tuning\n",
    "        #lambda_dt = 1\n",
    "        #probs = probs * lambda_z.unsqueeze(-1) * lambda_dt\n",
    "        #norm_factor = torch.maximum(1., probs.sum(dim=-1))  #F, T, T\n",
    "        #probs_norm = (probs / norm_factor[..., None])  #F, T, T, J\n",
    "\n",
    "        #total_probs = torch.sum(probs_norm, dim=-1)  # F, T, T\n",
    "        #compl_total_probs = 1 - total_probs  # F, T, T\n",
    "        #remaining_compl_probs = torch.cumprod(compl_total_probs, dim=-1)  # F, T, T\n",
    "        #off_probs = torch.sum(probs_norm * player_teams, dim=-1)\n",
    "        #def_probs = torch.sum(probs_norm * (1 - player_teams), dim=-1)\n",
    "\n",
    "        # maximum 0 because if it goes negative the pass has been caught by then and theres no residual probability\n",
    "\n",
    "        #shift_compl_cumsum = torch.roll(remaining_compl_probs, 1, dim=-1)  # F, T, T\n",
    "        #shift_compl_cumsum[:, :, 0] = 1\n",
    "        #total_completion_prob_dt = shift_compl_cumsum * total_probs  # F, T, T\n",
    "        #total_completion_prob = torch.cumsum(total_completion_prob_dt, dim=-1)  # F, T, T\n",
    "\n",
    "        #completion_prob_off_dt = shift_compl_cumsum * off_probs  # F, T, T\n",
    "        #completion_prob_def_dt = shift_compl_cumsum * def_probs  # F, T, T\n",
    "        #completion_prob_off = torch.cumsum(completion_prob_off_dt, dim=-1)  # F, T, T\n",
    "        #completion_prob_def = torch.cumsum(completion_prob_def_dt, dim=-1)  # F, T, T\n",
    "        \n",
    "        # this einsum takes the diagonal values over the last two axes\n",
    "        # where T = t. this takes care of the t > T issue.\n",
    "        #throw_p_int_off = torch.einsum('ijj->ij', total_completion_prob_off)  # F, T\n",
    "        #throw_p_int_def = torch.einsum('ijj->ij', total_completion_prob_def)  # F, T\n",
    "        #throw_p_int = torch.einsum('ijj->ij', total_completion_prob)  # F, T\n",
    "        \n",
    "        # below gets cutoff for combined model\n",
    "        #field_p_int_off = throw_p_int_off.mean(dim=1)  # F,\n",
    "        #field_p_int_def = throw_p_int_def.mean(dim=1)  # F,\n",
    "        #field_p_int = throw_p_int.mean(dim=1)  # F,\n",
    "\n",
    "        #field_p_no_int = 1-field_p_int\n",
    "\n",
    "        #field_df = pd.DataFrame({\n",
    "        #    'ball_start_x': ball_start[0],\n",
    "        #    'ball_start_y': ball_start[1], \n",
    "        #    'ball_end_x': field_locs[:,0],\n",
    "        #    'ball_end_y': field_locs[:,1],\n",
    "        #    'p_mass_1': (((field_p_int_off-field_p_int_def)+1.)/2.).round(3),\n",
    "        #    'p_mass_2': field_p_no_int.round(3),\n",
    "            # 'p_mass_players': p_int_norm,\n",
    "        #})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Dataset, Model and Run Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = PlaysDataset(data_dir = '../data/', all_weeks=True)\n",
    "loader = torch.utils.data.DataLoader(ds, batch_size=16, num_workers=4, shuffle=True)\n",
    "data, label = ds[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
      "Wall time: 4.77 µs\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'CompProbModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b0a9c1e57ea1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCompProbModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtti_sigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CompProbModel' is not defined"
     ]
    }
   ],
   "source": [
    "%time\n",
    "from tqdm.notebook import tqdm\n",
    "model = CompProbModel(tti_sigma=0.5)\n",
    "\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "prog_bar = tqdm(loader)\n",
    "\n",
    "for data, target in prog_bar:\n",
    "    output = model(data)\n",
    "    loss = loss_fn(output, target.float())\n",
    "    \n",
    "    # step gradient\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    prog_bar.set_description(\"Loss %.3f\" % loss.detach().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.8471], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1.]),\n",
       " Parameter containing:\n",
       " tensor([[  0.5000,  -0.2000],\n",
       "         [  0.5000,   0.5000],\n",
       "         [  0.5000,   1.5000],\n",
       "         ...,\n",
       "         [119.5000,  51.5000],\n",
       "         [119.5000,  52.5000],\n",
       "         [119.5000,  53.5000]]),\n",
       " Parameter containing:\n",
       " tensor([0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000, 0.9000,\n",
       "         1.0000, 1.1000, 1.2000, 1.3000, 1.4000, 1.5000, 1.6000, 1.7000, 1.8000,\n",
       "         1.9000, 2.0000, 2.1000, 2.2000, 2.3000, 2.4000, 2.5000, 2.6000, 2.7000,\n",
       "         2.8000, 2.9000, 3.0000, 3.1000, 3.2000, 3.3000, 3.4000, 3.5000, 3.6000,\n",
       "         3.7000, 3.8000, 3.9000, 4.0000])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tti_sigma\n",
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load files\n",
    "data_dir = '../data/'\n",
    "tracking_df = pd.read_csv('../data/week1_norm.csv')\n",
    "plays_df = pd.read_csv('../data/plays.csv')\n",
    "\n",
    "#print(tracking_df.columns)\n",
    "\n",
    "# get valid frames for tuning from tracking df\n",
    "tracking_df = tracking_df[tracking_df['event'].isin(['pass_forward', 'pass_arrived', \n",
    "    'pass_outcome_caught', 'pass_outcome_incomplete', 'pass_outcome_touchdown', 'pass_outcome_intercepted'])]\n",
    "tracking_df['valid_frame'] = tracking_df['event'].str.contains('pass_forward')\n",
    "tracking_df = tracking_df.groupby(['playId', 'gameId']).filter(lambda l: l['valid_frame'].any()).reset_index()\n",
    "\n",
    "# merge tracking df and plays df\n",
    "all_plays = plays_df.merge(tracking_df, how='left', on=['playId', 'gameId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-09 17:04:03+00:00\n",
      "2018-09-09 17:04:04.500000+00:00\n",
      "1.5\n"
     ]
    }
   ],
   "source": [
    "play = tracking_df[(tracking_df.playId == 81) & (tracking_df.gameId == 2018090902)]\n",
    "print(pd.to_timedelta(pd.to_datetime(play[play.event == 'pass_arrived'].time.iloc[0]) - pd.to_datetime(play[play.event == 'pass_forward'].time.iloc[0])).total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracking_df[tracking_df.position != 'QB'][['gameId', 'playId', 'nflId']].drop_duplicates().groupby(['gameId', 'playId']).nflId.count().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.085102305866526\n",
      "1.6439466513218899\n",
      "4.790180627434475\n",
      "2.435306899869004\n"
     ]
    }
   ],
   "source": [
    "min_dist_off = min_dist_off.rename(columns={0:'ball_dist'})\n",
    "complete_passes = all_plays.loc[all_plays.event.isin(['pass_outcome_caught', 'pass_outcome_touchdown'])][['gameId', 'playId']]\n",
    "incomplete_passes = all_plays.loc[all_plays.event.isin(['pass_outcome_incomplete'])][['gameId', 'playId']]\n",
    "\n",
    "print(complete_passes.merge(min_dist_off).drop_duplicates().ball_dist.median())\n",
    "print(incomplete_passes.merge(min_dist_off).drop_duplicates().ball_dist.mean())\n",
    "\n",
    "min_dist_def = min_dist_def.rename(columns={0:'ball_dist'})\n",
    "complete_passes = all_plays.loc[all_plays.event.isin(['pass_outcome_caught', 'pass_outcome_touchdown'])][['gameId', 'playId']]\n",
    "incomplete_passes = all_plays.loc[all_plays.event.isin(['pass_outcome_incomplete'])][['gameId', 'playId']]\n",
    "\n",
    "print(complete_passes.merge(min_dist_def).drop_duplicates().ball_dist.mean())\n",
    "print(incomplete_passes.merge(min_dist_def).drop_duplicates().ball_dist.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_plays.loc[(all_plays.gameId == 2018090600) & (all_plays.playId == 146)][['displayName', 'x', 'y']]\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from visualize2 import AnimatePlay\n",
    "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n",
    "play_df = tracking_df[(tracking_df.gameId == 2018091000) & (tracking_df.playId == 3016)]\n",
    "\n",
    "animated_play = AnimatePlay(play_df, 20)#play_df[play_df.frameId <= 46], 20)\n",
    "HTML(animated_play.ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_nearest_player(play_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
